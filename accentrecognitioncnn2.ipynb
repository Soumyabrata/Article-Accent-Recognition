{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Libraries\n\n! pip install --user pycm\n\nimport os, cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom keras import backend as K\nfrom keras.models import Model, Sequential\nfrom keras.layers import Dropout, Flatten, Dense, Activation, Conv2D, MaxPooling2D\nfrom keras.optimizers import Adam\nfrom keras.utils import to_categorical\n\nimport os, cv2\nfrom tqdm import tqdm\n\nfrom pycm import *","execution_count":16,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: pycm in /root/.local/lib/python3.7/site-packages (2.8)\nRequirement already satisfied: art>=1.8 in /root/.local/lib/python3.7/site-packages (from pycm) (4.7)\nRequirement already satisfied: numpy>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from pycm) (1.18.1)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=[]\nZ=[]\n\nIMG_SIZE=256\n\nACCENT_ENGLISH_DIR='../input/accent-data/english/'\nACCENT_FRENCH_DIR='../input/accent-data/french/'\nACCENT_GERMAN_DIR='../input/accent-data/german/'\nACCENT_HINDI_DIR='../input/accent-data/hindi/'\nACCENT_ARABIC_DIR='../input/accent-data/arabic/'","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def target(img, nationality):\n    return nationality","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_creation(nationality,DIR):\n    for img in tqdm(os.listdir(DIR)):\n        name = img\n        label = target(img,nationality)\n        path = os.path.join(DIR,img)\n        img = cv2.imread(path,cv2.IMREAD_COLOR)\n        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n        \n        X.append(np.array(img))\n        Z.append([str(label),name])","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creation of the data corresponding to the 5 accents\n\ndata_creation('english',ACCENT_ENGLISH_DIR)\ndata_creation('french',ACCENT_FRENCH_DIR)\ndata_creation('german',ACCENT_GERMAN_DIR)\ndata_creation('hindi',ACCENT_HINDI_DIR)\ndata_creation('arabic',ACCENT_ARABIC_DIR)","execution_count":20,"outputs":[{"output_type":"stream","text":"100%|██████████| 148/148 [00:01<00:00, 100.87it/s]\n100%|██████████| 63/63 [00:00<00:00, 101.00it/s]\n100%|██████████| 36/36 [00:00<00:00, 78.95it/s]\n100%|██████████| 18/18 [00:00<00:00, 98.52it/s]\n100%|██████████| 102/102 [00:00<00:00, 102.12it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def equal_list(l1, l2):\n    for i in range(len(l2)):\n        if l1[i] != l2[i]:\n            return False\n    return True","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We transform the data in a way understandable by a Deep-Learning model\n\nle = LabelEncoder()\nL = []\nfor i in range(len(Z)):\n    L.append(Z[i][0])\nY = le.fit_transform(L)\nY = to_categorical(Y,5)\nl = []\nfor i in range(len(Y)):\n    l.append([Y[i], Z[i][1]])\nY = l\nX = np.array(X)\nX = X/255\n\nx_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.25)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We build y_train and y_test (with just the labels)\n\ntrain_list = []\nfor l in y_train:\n    train_list.append(l[0])\n\ntest_list = []\nfor l in y_test:\n    test_list.append(l[0])\n\ny_train = train_list\ny_test = test_list","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We turn y_train and y_test into a single array, so we can use it in the model\n\nfor i in range(len(y_train)):\n    y_train[i] = list(y_train[i])\ny_train = np.asarray(y_train)\n\nfor i in range(len(y_test)):\n    y_test[i] = list(y_test[i])\ny_test = np.asarray(y_test)\n\ny_test[:10]","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"array([[1., 0., 0., 0., 0.],\n       [1., 0., 0., 0., 0.],\n       [1., 0., 0., 0., 0.],\n       [1., 0., 0., 0., 0.],\n       [1., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 0., 1., 0.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 0., 1., 0.]], dtype=float32)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# **Convolutional Neural Network**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convolutional Network\nmodel = Sequential()\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',activation ='relu', input_shape = (256,256,3)))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dense(5, activation = \"softmax\"))\n\nmodel.compile(optimizer=Adam(),loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.summary()","execution_count":25,"outputs":[{"output_type":"stream","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_2 (Conv2D)            (None, 256, 256, 32)      2432      \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 128, 128, 32)      0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 128, 128, 64)      18496     \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 64, 64, 64)        0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 262144)            0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 512)               134218240 \n_________________________________________________________________\nactivation_1 (Activation)    (None, 512)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 5)                 2565      \n=================================================================\nTotal params: 134,241,733\nTrainable params: 134,241,733\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size=50\nepochs=500\n\nhistory = model.fit(x_train,y_train,epochs=epochs,batch_size=batch_size,validation_data = (x_test,y_test))","execution_count":26,"outputs":[{"output_type":"stream","text":"Epoch 1/500\n6/6 [==============================] - 1s 112ms/step - loss: 31.9047 - accuracy: 0.3309 - val_loss: 9.5602 - val_accuracy: 0.3804\nEpoch 2/500\n6/6 [==============================] - 1s 95ms/step - loss: 3.6182 - accuracy: 0.3309 - val_loss: 1.1404 - val_accuracy: 0.6848\nEpoch 3/500\n6/6 [==============================] - 1s 91ms/step - loss: 1.1315 - accuracy: 0.6764 - val_loss: 1.0118 - val_accuracy: 0.5543\nEpoch 4/500\n6/6 [==============================] - 1s 92ms/step - loss: 0.9768 - accuracy: 0.6218 - val_loss: 0.7931 - val_accuracy: 0.5870\nEpoch 5/500\n6/6 [==============================] - 1s 91ms/step - loss: 0.8365 - accuracy: 0.6545 - val_loss: 0.7243 - val_accuracy: 0.7065\nEpoch 6/500\n6/6 [==============================] - 1s 94ms/step - loss: 0.7082 - accuracy: 0.7055 - val_loss: 0.6998 - val_accuracy: 0.7609\nEpoch 7/500\n6/6 [==============================] - 1s 96ms/step - loss: 0.7006 - accuracy: 0.6836 - val_loss: 0.8410 - val_accuracy: 0.6957\nEpoch 8/500\n6/6 [==============================] - 1s 97ms/step - loss: 0.5874 - accuracy: 0.7782 - val_loss: 0.8120 - val_accuracy: 0.6957\nEpoch 9/500\n6/6 [==============================] - 1s 95ms/step - loss: 0.4218 - accuracy: 0.8473 - val_loss: 1.1507 - val_accuracy: 0.7065\nEpoch 10/500\n6/6 [==============================] - 1s 96ms/step - loss: 0.5269 - accuracy: 0.7964 - val_loss: 0.6977 - val_accuracy: 0.7174\nEpoch 11/500\n6/6 [==============================] - 1s 90ms/step - loss: 0.3830 - accuracy: 0.8873 - val_loss: 0.8655 - val_accuracy: 0.6957\nEpoch 12/500\n6/6 [==============================] - 1s 92ms/step - loss: 0.2758 - accuracy: 0.9164 - val_loss: 0.7733 - val_accuracy: 0.7391\nEpoch 13/500\n6/6 [==============================] - 1s 107ms/step - loss: 0.1881 - accuracy: 0.9527 - val_loss: 0.7355 - val_accuracy: 0.7174\nEpoch 14/500\n6/6 [==============================] - 1s 98ms/step - loss: 0.1434 - accuracy: 0.9673 - val_loss: 0.7508 - val_accuracy: 0.7283\nEpoch 15/500\n6/6 [==============================] - 1s 92ms/step - loss: 0.1175 - accuracy: 0.9745 - val_loss: 0.9640 - val_accuracy: 0.6848\nEpoch 16/500\n6/6 [==============================] - 1s 93ms/step - loss: 0.0890 - accuracy: 0.9927 - val_loss: 0.9120 - val_accuracy: 0.7283\nEpoch 17/500\n6/6 [==============================] - 1s 94ms/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 1.0572 - val_accuracy: 0.6522\nEpoch 18/500\n6/6 [==============================] - 1s 89ms/step - loss: 0.0772 - accuracy: 0.9891 - val_loss: 1.0500 - val_accuracy: 0.7283\nEpoch 19/500\n6/6 [==============================] - 1s 90ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 1.0125 - val_accuracy: 0.6848\nEpoch 20/500\n6/6 [==============================] - 1s 92ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 1.0665 - val_accuracy: 0.7391\nEpoch 21/500\n6/6 [==============================] - 1s 96ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.1190 - val_accuracy: 0.7065\nEpoch 22/500\n6/6 [==============================] - 1s 93ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.1402 - val_accuracy: 0.7391\nEpoch 23/500\n6/6 [==============================] - 1s 96ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.1662 - val_accuracy: 0.7283\nEpoch 24/500\n6/6 [==============================] - 1s 93ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.1696 - val_accuracy: 0.7391\nEpoch 25/500\n6/6 [==============================] - 1s 97ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.2861 - val_accuracy: 0.7065\nEpoch 26/500\n6/6 [==============================] - 1s 104ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1760 - val_accuracy: 0.7391\nEpoch 27/500\n6/6 [==============================] - 1s 89ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.3474 - val_accuracy: 0.7065\nEpoch 28/500\n6/6 [==============================] - 1s 93ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.2072 - val_accuracy: 0.7391\nEpoch 29/500\n6/6 [==============================] - 1s 93ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3182 - val_accuracy: 0.7283\nEpoch 30/500\n6/6 [==============================] - 1s 111ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2598 - val_accuracy: 0.7283\nEpoch 31/500\n6/6 [==============================] - 1s 92ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3709 - val_accuracy: 0.7391\nEpoch 32/500\n6/6 [==============================] - 1s 91ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2726 - val_accuracy: 0.7283\nEpoch 33/500\n6/6 [==============================] - 1s 93ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3664 - val_accuracy: 0.7283\nEpoch 34/500\n6/6 [==============================] - 1s 94ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3167 - val_accuracy: 0.7283\nEpoch 35/500\n6/6 [==============================] - 1s 93ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3618 - val_accuracy: 0.7174\nEpoch 36/500\n6/6 [==============================] - 1s 91ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3767 - val_accuracy: 0.7283\nEpoch 37/500\n6/6 [==============================] - 1s 95ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3433 - val_accuracy: 0.7174\nEpoch 38/500\n6/6 [==============================] - 1s 89ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3958 - val_accuracy: 0.7283\nEpoch 39/500\n6/6 [==============================] - 1s 92ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3980 - val_accuracy: 0.7174\nEpoch 40/500\n6/6 [==============================] - 1s 96ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3889 - val_accuracy: 0.7174\nEpoch 41/500\n6/6 [==============================] - 1s 95ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.4229 - val_accuracy: 0.7174\nEpoch 42/500\n6/6 [==============================] - 1s 93ms/step - loss: 9.6712e-04 - accuracy: 1.0000 - val_loss: 1.4399 - val_accuracy: 0.7283\nEpoch 43/500\n6/6 [==============================] - 1s 92ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.3383 - val_accuracy: 0.7283\nEpoch 44/500\n6/6 [==============================] - 1s 96ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.5649 - val_accuracy: 0.7174\nEpoch 45/500\n6/6 [==============================] - 1s 92ms/step - loss: 9.0556e-04 - accuracy: 1.0000 - val_loss: 1.3511 - val_accuracy: 0.7391\nEpoch 46/500\n6/6 [==============================] - 1s 93ms/step - loss: 7.9116e-04 - accuracy: 1.0000 - val_loss: 1.6109 - val_accuracy: 0.7174\nEpoch 47/500\n6/6 [==============================] - 1s 104ms/step - loss: 8.4917e-04 - accuracy: 1.0000 - val_loss: 1.3203 - val_accuracy: 0.7283\nEpoch 48/500\n6/6 [==============================] - 1s 98ms/step - loss: 8.6461e-04 - accuracy: 1.0000 - val_loss: 1.5823 - val_accuracy: 0.7174\nEpoch 49/500\n6/6 [==============================] - 1s 92ms/step - loss: 8.0127e-04 - accuracy: 1.0000 - val_loss: 1.3634 - val_accuracy: 0.7283\nEpoch 50/500\n6/6 [==============================] - 1s 96ms/step - loss: 7.2235e-04 - accuracy: 1.0000 - val_loss: 1.5652 - val_accuracy: 0.7283\nEpoch 51/500\n6/6 [==============================] - 1s 95ms/step - loss: 6.3560e-04 - accuracy: 1.0000 - val_loss: 1.4062 - val_accuracy: 0.7283\nEpoch 52/500\n6/6 [==============================] - 1s 94ms/step - loss: 6.0077e-04 - accuracy: 1.0000 - val_loss: 1.5380 - val_accuracy: 0.7283\nEpoch 53/500\n6/6 [==============================] - 1s 97ms/step - loss: 5.7088e-04 - accuracy: 1.0000 - val_loss: 1.4492 - val_accuracy: 0.7174\nEpoch 54/500\n6/6 [==============================] - 1s 100ms/step - loss: 5.9006e-04 - accuracy: 1.0000 - val_loss: 1.5888 - val_accuracy: 0.7283\nEpoch 55/500\n6/6 [==============================] - 1s 94ms/step - loss: 5.8117e-04 - accuracy: 1.0000 - val_loss: 1.4558 - val_accuracy: 0.7174\nEpoch 56/500\n6/6 [==============================] - 1s 92ms/step - loss: 5.1759e-04 - accuracy: 1.0000 - val_loss: 1.5494 - val_accuracy: 0.7174\nEpoch 57/500\n6/6 [==============================] - 1s 89ms/step - loss: 4.6830e-04 - accuracy: 1.0000 - val_loss: 1.4891 - val_accuracy: 0.7283\nEpoch 58/500\n6/6 [==============================] - 1s 94ms/step - loss: 4.4288e-04 - accuracy: 1.0000 - val_loss: 1.5478 - val_accuracy: 0.7174\n","name":"stdout"},{"output_type":"stream","text":"Epoch 59/500\n6/6 [==============================] - 1s 93ms/step - loss: 4.4513e-04 - accuracy: 1.0000 - val_loss: 1.5018 - val_accuracy: 0.7174\nEpoch 60/500\n6/6 [==============================] - 1s 92ms/step - loss: 4.2921e-04 - accuracy: 1.0000 - val_loss: 1.5657 - val_accuracy: 0.7283\nEpoch 61/500\n6/6 [==============================] - 1s 91ms/step - loss: 4.0437e-04 - accuracy: 1.0000 - val_loss: 1.5339 - val_accuracy: 0.7174\nEpoch 62/500\n6/6 [==============================] - 1s 93ms/step - loss: 3.7091e-04 - accuracy: 1.0000 - val_loss: 1.5751 - val_accuracy: 0.7283\nEpoch 63/500\n6/6 [==============================] - 1s 96ms/step - loss: 3.9471e-04 - accuracy: 1.0000 - val_loss: 1.5252 - val_accuracy: 0.7065\nEpoch 64/500\n6/6 [==============================] - 1s 105ms/step - loss: 3.8229e-04 - accuracy: 1.0000 - val_loss: 1.5641 - val_accuracy: 0.7174\nEpoch 65/500\n6/6 [==============================] - 1s 93ms/step - loss: 3.5762e-04 - accuracy: 1.0000 - val_loss: 1.5952 - val_accuracy: 0.7283\nEpoch 66/500\n6/6 [==============================] - 1s 122ms/step - loss: 3.2203e-04 - accuracy: 1.0000 - val_loss: 1.5403 - val_accuracy: 0.7174\nEpoch 67/500\n6/6 [==============================] - 1s 97ms/step - loss: 3.0762e-04 - accuracy: 1.0000 - val_loss: 1.5958 - val_accuracy: 0.7174\nEpoch 68/500\n6/6 [==============================] - 1s 95ms/step - loss: 2.9777e-04 - accuracy: 1.0000 - val_loss: 1.5692 - val_accuracy: 0.7174\nEpoch 69/500\n6/6 [==============================] - 1s 94ms/step - loss: 2.8330e-04 - accuracy: 1.0000 - val_loss: 1.5962 - val_accuracy: 0.7174\nEpoch 70/500\n6/6 [==============================] - 1s 95ms/step - loss: 2.6870e-04 - accuracy: 1.0000 - val_loss: 1.6034 - val_accuracy: 0.7283\nEpoch 71/500\n6/6 [==============================] - 1s 98ms/step - loss: 2.5605e-04 - accuracy: 1.0000 - val_loss: 1.5703 - val_accuracy: 0.7174\nEpoch 72/500\n6/6 [==============================] - 1s 93ms/step - loss: 2.6541e-04 - accuracy: 1.0000 - val_loss: 1.6512 - val_accuracy: 0.7283\nEpoch 73/500\n6/6 [==============================] - 1s 99ms/step - loss: 2.4184e-04 - accuracy: 1.0000 - val_loss: 1.5800 - val_accuracy: 0.7174\nEpoch 74/500\n6/6 [==============================] - 1s 141ms/step - loss: 2.3505e-04 - accuracy: 1.0000 - val_loss: 1.5999 - val_accuracy: 0.7174\nEpoch 75/500\n6/6 [==============================] - 1s 98ms/step - loss: 2.1561e-04 - accuracy: 1.0000 - val_loss: 1.6123 - val_accuracy: 0.7174\nEpoch 76/500\n6/6 [==============================] - 1s 91ms/step - loss: 2.2671e-04 - accuracy: 1.0000 - val_loss: 1.5814 - val_accuracy: 0.7174\nEpoch 77/500\n6/6 [==============================] - 1s 90ms/step - loss: 2.1477e-04 - accuracy: 1.0000 - val_loss: 1.6402 - val_accuracy: 0.7174\nEpoch 78/500\n6/6 [==============================] - 1s 94ms/step - loss: 2.0127e-04 - accuracy: 1.0000 - val_loss: 1.5735 - val_accuracy: 0.7174\nEpoch 79/500\n6/6 [==============================] - 1s 90ms/step - loss: 1.9448e-04 - accuracy: 1.0000 - val_loss: 1.6716 - val_accuracy: 0.7174\nEpoch 80/500\n6/6 [==============================] - 1s 111ms/step - loss: 1.7544e-04 - accuracy: 1.0000 - val_loss: 1.6163 - val_accuracy: 0.7174\nEpoch 81/500\n6/6 [==============================] - 1s 97ms/step - loss: 1.6596e-04 - accuracy: 1.0000 - val_loss: 1.6332 - val_accuracy: 0.7174\nEpoch 82/500\n6/6 [==============================] - 1s 97ms/step - loss: 1.5621e-04 - accuracy: 1.0000 - val_loss: 1.6671 - val_accuracy: 0.7174\nEpoch 83/500\n6/6 [==============================] - 1s 96ms/step - loss: 1.5521e-04 - accuracy: 1.0000 - val_loss: 1.5954 - val_accuracy: 0.7174\nEpoch 84/500\n6/6 [==============================] - 1s 91ms/step - loss: 1.5166e-04 - accuracy: 1.0000 - val_loss: 1.6530 - val_accuracy: 0.7174\nEpoch 85/500\n6/6 [==============================] - 1s 96ms/step - loss: 1.3457e-04 - accuracy: 1.0000 - val_loss: 1.6685 - val_accuracy: 0.7174\nEpoch 86/500\n6/6 [==============================] - 1s 89ms/step - loss: 1.3101e-04 - accuracy: 1.0000 - val_loss: 1.6272 - val_accuracy: 0.7174\nEpoch 87/500\n6/6 [==============================] - 1s 94ms/step - loss: 1.2268e-04 - accuracy: 1.0000 - val_loss: 1.6894 - val_accuracy: 0.7174\nEpoch 88/500\n6/6 [==============================] - 1s 91ms/step - loss: 1.1608e-04 - accuracy: 1.0000 - val_loss: 1.6931 - val_accuracy: 0.7174\nEpoch 89/500\n6/6 [==============================] - 1s 93ms/step - loss: 1.0915e-04 - accuracy: 1.0000 - val_loss: 1.6784 - val_accuracy: 0.7174\nEpoch 90/500\n6/6 [==============================] - 1s 95ms/step - loss: 1.0819e-04 - accuracy: 1.0000 - val_loss: 1.7293 - val_accuracy: 0.7283\nEpoch 91/500\n6/6 [==============================] - 1s 93ms/step - loss: 1.0006e-04 - accuracy: 1.0000 - val_loss: 1.6438 - val_accuracy: 0.7174\nEpoch 92/500\n6/6 [==============================] - 1s 97ms/step - loss: 9.7546e-05 - accuracy: 1.0000 - val_loss: 1.6803 - val_accuracy: 0.7174\nEpoch 93/500\n6/6 [==============================] - 1s 94ms/step - loss: 9.5244e-05 - accuracy: 1.0000 - val_loss: 1.7752 - val_accuracy: 0.7174\nEpoch 94/500\n6/6 [==============================] - 1s 93ms/step - loss: 9.2909e-05 - accuracy: 1.0000 - val_loss: 1.6314 - val_accuracy: 0.7391\nEpoch 95/500\n6/6 [==============================] - 1s 90ms/step - loss: 8.7654e-05 - accuracy: 1.0000 - val_loss: 1.7266 - val_accuracy: 0.7174\nEpoch 96/500\n6/6 [==============================] - 1s 93ms/step - loss: 7.9951e-05 - accuracy: 1.0000 - val_loss: 1.7208 - val_accuracy: 0.7283\nEpoch 97/500\n6/6 [==============================] - 1s 109ms/step - loss: 8.0153e-05 - accuracy: 1.0000 - val_loss: 1.7233 - val_accuracy: 0.7065\nEpoch 98/500\n6/6 [==============================] - 1s 90ms/step - loss: 7.0604e-05 - accuracy: 1.0000 - val_loss: 1.7407 - val_accuracy: 0.7283\nEpoch 99/500\n6/6 [==============================] - 1s 91ms/step - loss: 7.3288e-05 - accuracy: 1.0000 - val_loss: 1.6613 - val_accuracy: 0.7283\nEpoch 100/500\n6/6 [==============================] - 1s 95ms/step - loss: 7.4514e-05 - accuracy: 1.0000 - val_loss: 1.8647 - val_accuracy: 0.7391\nEpoch 101/500\n6/6 [==============================] - 1s 98ms/step - loss: 8.6574e-05 - accuracy: 1.0000 - val_loss: 1.6538 - val_accuracy: 0.7283\nEpoch 102/500\n6/6 [==============================] - 1s 93ms/step - loss: 6.5457e-05 - accuracy: 1.0000 - val_loss: 1.8356 - val_accuracy: 0.7283\nEpoch 103/500\n6/6 [==============================] - 1s 92ms/step - loss: 6.1091e-05 - accuracy: 1.0000 - val_loss: 1.6864 - val_accuracy: 0.7500\nEpoch 104/500\n6/6 [==============================] - 1s 95ms/step - loss: 4.8916e-05 - accuracy: 1.0000 - val_loss: 1.8286 - val_accuracy: 0.7283\nEpoch 105/500\n6/6 [==============================] - 1s 91ms/step - loss: 4.6465e-05 - accuracy: 1.0000 - val_loss: 1.6643 - val_accuracy: 0.7283\nEpoch 106/500\n6/6 [==============================] - 1s 93ms/step - loss: 5.0026e-05 - accuracy: 1.0000 - val_loss: 1.8270 - val_accuracy: 0.7283\nEpoch 107/500\n6/6 [==============================] - 1s 96ms/step - loss: 4.4260e-05 - accuracy: 1.0000 - val_loss: 1.7256 - val_accuracy: 0.7500\nEpoch 108/500\n6/6 [==============================] - 1s 93ms/step - loss: 4.2606e-05 - accuracy: 1.0000 - val_loss: 1.7639 - val_accuracy: 0.7283\nEpoch 109/500\n6/6 [==============================] - 1s 92ms/step - loss: 4.0466e-05 - accuracy: 1.0000 - val_loss: 1.8233 - val_accuracy: 0.7283\nEpoch 110/500\n6/6 [==============================] - 1s 97ms/step - loss: 3.7957e-05 - accuracy: 1.0000 - val_loss: 1.7116 - val_accuracy: 0.7500\nEpoch 111/500\n6/6 [==============================] - 1s 91ms/step - loss: 3.6054e-05 - accuracy: 1.0000 - val_loss: 1.8190 - val_accuracy: 0.7283\nEpoch 112/500\n6/6 [==============================] - 1s 92ms/step - loss: 3.2461e-05 - accuracy: 1.0000 - val_loss: 1.7731 - val_accuracy: 0.7391\nEpoch 113/500\n6/6 [==============================] - 1s 95ms/step - loss: 3.0578e-05 - accuracy: 1.0000 - val_loss: 1.8028 - val_accuracy: 0.7283\nEpoch 114/500\n6/6 [==============================] - 1s 107ms/step - loss: 2.9252e-05 - accuracy: 1.0000 - val_loss: 1.8196 - val_accuracy: 0.7283\nEpoch 115/500\n","name":"stdout"},{"output_type":"stream","text":"6/6 [==============================] - 1s 95ms/step - loss: 2.7549e-05 - accuracy: 1.0000 - val_loss: 1.7545 - val_accuracy: 0.7500\nEpoch 116/500\n6/6 [==============================] - 1s 95ms/step - loss: 2.7088e-05 - accuracy: 1.0000 - val_loss: 1.8711 - val_accuracy: 0.7283\nEpoch 117/500\n6/6 [==============================] - 1s 92ms/step - loss: 2.5841e-05 - accuracy: 1.0000 - val_loss: 1.7839 - val_accuracy: 0.7500\nEpoch 118/500\n6/6 [==============================] - 1s 94ms/step - loss: 2.4131e-05 - accuracy: 1.0000 - val_loss: 1.8544 - val_accuracy: 0.7283\nEpoch 119/500\n6/6 [==============================] - 1s 96ms/step - loss: 2.4246e-05 - accuracy: 1.0000 - val_loss: 1.8790 - val_accuracy: 0.7283\nEpoch 120/500\n6/6 [==============================] - 1s 98ms/step - loss: 2.3777e-05 - accuracy: 1.0000 - val_loss: 1.7845 - val_accuracy: 0.7500\nEpoch 121/500\n6/6 [==============================] - 1s 101ms/step - loss: 2.2171e-05 - accuracy: 1.0000 - val_loss: 1.8084 - val_accuracy: 0.7500\nEpoch 122/500\n6/6 [==============================] - 1s 102ms/step - loss: 2.2075e-05 - accuracy: 1.0000 - val_loss: 1.9339 - val_accuracy: 0.7283\nEpoch 123/500\n6/6 [==============================] - 1s 95ms/step - loss: 2.0245e-05 - accuracy: 1.0000 - val_loss: 1.7709 - val_accuracy: 0.7500\nEpoch 124/500\n6/6 [==============================] - 1s 91ms/step - loss: 1.9777e-05 - accuracy: 1.0000 - val_loss: 1.8775 - val_accuracy: 0.7283\nEpoch 125/500\n6/6 [==============================] - 1s 96ms/step - loss: 1.8514e-05 - accuracy: 1.0000 - val_loss: 1.8846 - val_accuracy: 0.7283\nEpoch 126/500\n6/6 [==============================] - 1s 90ms/step - loss: 1.9292e-05 - accuracy: 1.0000 - val_loss: 1.7576 - val_accuracy: 0.7500\nEpoch 127/500\n6/6 [==============================] - 1s 94ms/step - loss: 1.8807e-05 - accuracy: 1.0000 - val_loss: 1.9864 - val_accuracy: 0.7283\nEpoch 128/500\n6/6 [==============================] - 1s 92ms/step - loss: 1.6905e-05 - accuracy: 1.0000 - val_loss: 1.7942 - val_accuracy: 0.7500\nEpoch 129/500\n6/6 [==============================] - 1s 102ms/step - loss: 1.6164e-05 - accuracy: 1.0000 - val_loss: 1.9699 - val_accuracy: 0.7283\nEpoch 130/500\n6/6 [==============================] - 1s 105ms/step - loss: 1.4461e-05 - accuracy: 1.0000 - val_loss: 1.8427 - val_accuracy: 0.7500\nEpoch 131/500\n6/6 [==============================] - 1s 99ms/step - loss: 1.3177e-05 - accuracy: 1.0000 - val_loss: 1.9215 - val_accuracy: 0.7283\nEpoch 132/500\n6/6 [==============================] - 1s 90ms/step - loss: 1.2494e-05 - accuracy: 1.0000 - val_loss: 1.8703 - val_accuracy: 0.7500\nEpoch 133/500\n6/6 [==============================] - 1s 97ms/step - loss: 1.1897e-05 - accuracy: 1.0000 - val_loss: 1.8987 - val_accuracy: 0.7391\nEpoch 134/500\n6/6 [==============================] - 1s 96ms/step - loss: 1.0799e-05 - accuracy: 1.0000 - val_loss: 1.8895 - val_accuracy: 0.7500\nEpoch 135/500\n6/6 [==============================] - 1s 94ms/step - loss: 1.0814e-05 - accuracy: 1.0000 - val_loss: 1.8937 - val_accuracy: 0.7500\nEpoch 136/500\n6/6 [==============================] - 1s 91ms/step - loss: 1.1463e-05 - accuracy: 1.0000 - val_loss: 1.9622 - val_accuracy: 0.7283\nEpoch 137/500\n6/6 [==============================] - 1s 96ms/step - loss: 1.0443e-05 - accuracy: 1.0000 - val_loss: 1.9321 - val_accuracy: 0.7283\nEpoch 138/500\n6/6 [==============================] - 1s 94ms/step - loss: 9.4612e-06 - accuracy: 1.0000 - val_loss: 1.9305 - val_accuracy: 0.7391\nEpoch 139/500\n6/6 [==============================] - 1s 99ms/step - loss: 8.6731e-06 - accuracy: 1.0000 - val_loss: 1.9615 - val_accuracy: 0.7283\nEpoch 140/500\n6/6 [==============================] - 1s 90ms/step - loss: 8.3433e-06 - accuracy: 1.0000 - val_loss: 1.8777 - val_accuracy: 0.7500\nEpoch 141/500\n6/6 [==============================] - 1s 94ms/step - loss: 8.6246e-06 - accuracy: 1.0000 - val_loss: 1.9875 - val_accuracy: 0.7283\nEpoch 142/500\n6/6 [==============================] - 1s 96ms/step - loss: 7.9735e-06 - accuracy: 1.0000 - val_loss: 1.9662 - val_accuracy: 0.7283\nEpoch 143/500\n6/6 [==============================] - 1s 92ms/step - loss: 7.9618e-06 - accuracy: 1.0000 - val_loss: 1.9148 - val_accuracy: 0.7500\nEpoch 144/500\n6/6 [==============================] - 1s 95ms/step - loss: 7.5790e-06 - accuracy: 1.0000 - val_loss: 2.0362 - val_accuracy: 0.7283\nEpoch 145/500\n6/6 [==============================] - 1s 94ms/step - loss: 7.4646e-06 - accuracy: 1.0000 - val_loss: 1.9095 - val_accuracy: 0.7500\nEpoch 146/500\n6/6 [==============================] - 1s 95ms/step - loss: 7.0186e-06 - accuracy: 1.0000 - val_loss: 2.0482 - val_accuracy: 0.7283\nEpoch 147/500\n6/6 [==============================] - 1s 111ms/step - loss: 7.0892e-06 - accuracy: 1.0000 - val_loss: 1.9588 - val_accuracy: 0.7500\nEpoch 148/500\n6/6 [==============================] - 1s 98ms/step - loss: 6.2448e-06 - accuracy: 1.0000 - val_loss: 1.9820 - val_accuracy: 0.7391\nEpoch 149/500\n6/6 [==============================] - 1s 93ms/step - loss: 5.8456e-06 - accuracy: 1.0000 - val_loss: 1.9888 - val_accuracy: 0.7283\nEpoch 150/500\n6/6 [==============================] - 1s 96ms/step - loss: 5.5742e-06 - accuracy: 1.0000 - val_loss: 1.9719 - val_accuracy: 0.7500\nEpoch 151/500\n6/6 [==============================] - 1s 95ms/step - loss: 5.3930e-06 - accuracy: 1.0000 - val_loss: 2.0923 - val_accuracy: 0.7283\nEpoch 152/500\n6/6 [==============================] - 1s 96ms/step - loss: 5.2855e-06 - accuracy: 1.0000 - val_loss: 1.9457 - val_accuracy: 0.7500\nEpoch 153/500\n6/6 [==============================] - 1s 92ms/step - loss: 5.0154e-06 - accuracy: 1.0000 - val_loss: 2.0959 - val_accuracy: 0.7283\nEpoch 154/500\n6/6 [==============================] - 1s 92ms/step - loss: 5.5746e-06 - accuracy: 1.0000 - val_loss: 1.9963 - val_accuracy: 0.7500\nEpoch 155/500\n6/6 [==============================] - 1s 90ms/step - loss: 5.1177e-06 - accuracy: 1.0000 - val_loss: 1.9703 - val_accuracy: 0.7500\nEpoch 156/500\n6/6 [==============================] - 1s 94ms/step - loss: 4.6400e-06 - accuracy: 1.0000 - val_loss: 2.0940 - val_accuracy: 0.7283\nEpoch 157/500\n6/6 [==============================] - 1s 112ms/step - loss: 4.5958e-06 - accuracy: 1.0000 - val_loss: 1.9770 - val_accuracy: 0.7500\nEpoch 158/500\n6/6 [==============================] - 1s 96ms/step - loss: 4.2984e-06 - accuracy: 1.0000 - val_loss: 2.0477 - val_accuracy: 0.7283\nEpoch 159/500\n6/6 [==============================] - 1s 96ms/step - loss: 4.0826e-06 - accuracy: 1.0000 - val_loss: 2.0633 - val_accuracy: 0.7283\nEpoch 160/500\n6/6 [==============================] - 1s 90ms/step - loss: 3.9820e-06 - accuracy: 1.0000 - val_loss: 2.0010 - val_accuracy: 0.7500\nEpoch 161/500\n6/6 [==============================] - 1s 93ms/step - loss: 3.6322e-06 - accuracy: 1.0000 - val_loss: 2.1102 - val_accuracy: 0.7283\nEpoch 162/500\n6/6 [==============================] - 1s 96ms/step - loss: 3.6187e-06 - accuracy: 1.0000 - val_loss: 2.0079 - val_accuracy: 0.7500\nEpoch 163/500\n6/6 [==============================] - 1s 94ms/step - loss: 3.5091e-06 - accuracy: 1.0000 - val_loss: 2.0768 - val_accuracy: 0.7283\nEpoch 164/500\n6/6 [==============================] - 1s 142ms/step - loss: 3.3296e-06 - accuracy: 1.0000 - val_loss: 2.0511 - val_accuracy: 0.7391\nEpoch 165/500\n6/6 [==============================] - 1s 91ms/step - loss: 3.2832e-06 - accuracy: 1.0000 - val_loss: 2.0705 - val_accuracy: 0.7391\nEpoch 166/500\n6/6 [==============================] - 1s 97ms/step - loss: 3.2975e-06 - accuracy: 1.0000 - val_loss: 2.1402 - val_accuracy: 0.7283\nEpoch 167/500\n6/6 [==============================] - 1s 105ms/step - loss: 3.2377e-06 - accuracy: 1.0000 - val_loss: 2.0170 - val_accuracy: 0.7500\nEpoch 168/500\n6/6 [==============================] - 1s 93ms/step - loss: 3.0049e-06 - accuracy: 1.0000 - val_loss: 2.1513 - val_accuracy: 0.7283\nEpoch 169/500\n6/6 [==============================] - 1s 103ms/step - loss: 3.0895e-06 - accuracy: 1.0000 - val_loss: 2.1293 - val_accuracy: 0.7283\nEpoch 170/500\n6/6 [==============================] - 1s 96ms/step - loss: 3.0899e-06 - accuracy: 1.0000 - val_loss: 2.0249 - val_accuracy: 0.7500\nEpoch 171/500\n","name":"stdout"},{"output_type":"stream","text":"6/6 [==============================] - 1s 91ms/step - loss: 2.8094e-06 - accuracy: 1.0000 - val_loss: 2.1593 - val_accuracy: 0.7283\nEpoch 172/500\n6/6 [==============================] - 1s 94ms/step - loss: 2.8376e-06 - accuracy: 1.0000 - val_loss: 2.0850 - val_accuracy: 0.7391\nEpoch 173/500\n6/6 [==============================] - 1s 96ms/step - loss: 2.7284e-06 - accuracy: 1.0000 - val_loss: 2.0598 - val_accuracy: 0.7500\nEpoch 174/500\n6/6 [==============================] - 1s 89ms/step - loss: 2.7128e-06 - accuracy: 1.0000 - val_loss: 2.2045 - val_accuracy: 0.7283\nEpoch 175/500\n6/6 [==============================] - 1s 94ms/step - loss: 2.6226e-06 - accuracy: 1.0000 - val_loss: 2.0660 - val_accuracy: 0.7500\nEpoch 176/500\n6/6 [==============================] - 1s 93ms/step - loss: 2.4353e-06 - accuracy: 1.0000 - val_loss: 2.1344 - val_accuracy: 0.7283\nEpoch 177/500\n6/6 [==============================] - 1s 97ms/step - loss: 2.1999e-06 - accuracy: 1.0000 - val_loss: 2.1328 - val_accuracy: 0.7283\nEpoch 178/500\n6/6 [==============================] - 1s 92ms/step - loss: 2.1284e-06 - accuracy: 1.0000 - val_loss: 2.1150 - val_accuracy: 0.7391\nEpoch 179/500\n6/6 [==============================] - 1s 89ms/step - loss: 2.0859e-06 - accuracy: 1.0000 - val_loss: 2.1329 - val_accuracy: 0.7283\nEpoch 180/500\n6/6 [==============================] - 1s 103ms/step - loss: 2.0014e-06 - accuracy: 1.0000 - val_loss: 2.1453 - val_accuracy: 0.7283\nEpoch 181/500\n6/6 [==============================] - 1s 97ms/step - loss: 1.9511e-06 - accuracy: 1.0000 - val_loss: 2.1639 - val_accuracy: 0.7283\nEpoch 182/500\n6/6 [==============================] - 1s 93ms/step - loss: 1.8987e-06 - accuracy: 1.0000 - val_loss: 2.1376 - val_accuracy: 0.7283\nEpoch 183/500\n6/6 [==============================] - 1s 93ms/step - loss: 1.8649e-06 - accuracy: 1.0000 - val_loss: 2.2009 - val_accuracy: 0.7283\nEpoch 184/500\n6/6 [==============================] - 1s 94ms/step - loss: 2.0391e-06 - accuracy: 1.0000 - val_loss: 2.1515 - val_accuracy: 0.7283\nEpoch 185/500\n6/6 [==============================] - 1s 92ms/step - loss: 1.9659e-06 - accuracy: 1.0000 - val_loss: 2.1731 - val_accuracy: 0.7283\nEpoch 186/500\n6/6 [==============================] - 1s 96ms/step - loss: 1.8696e-06 - accuracy: 1.0000 - val_loss: 2.1398 - val_accuracy: 0.7283\nEpoch 187/500\n6/6 [==============================] - 1s 96ms/step - loss: 1.7179e-06 - accuracy: 1.0000 - val_loss: 2.1718 - val_accuracy: 0.7283\nEpoch 188/500\n6/6 [==============================] - 1s 96ms/step - loss: 1.6741e-06 - accuracy: 1.0000 - val_loss: 2.2046 - val_accuracy: 0.7283\nEpoch 189/500\n6/6 [==============================] - 1s 96ms/step - loss: 1.6191e-06 - accuracy: 1.0000 - val_loss: 2.1697 - val_accuracy: 0.7283\nEpoch 190/500\n6/6 [==============================] - 1s 97ms/step - loss: 1.5315e-06 - accuracy: 1.0000 - val_loss: 2.1929 - val_accuracy: 0.7283\nEpoch 191/500\n6/6 [==============================] - 1s 93ms/step - loss: 1.5371e-06 - accuracy: 1.0000 - val_loss: 2.1458 - val_accuracy: 0.7391\nEpoch 192/500\n6/6 [==============================] - 1s 93ms/step - loss: 1.4851e-06 - accuracy: 1.0000 - val_loss: 2.2225 - val_accuracy: 0.7283\nEpoch 193/500\n6/6 [==============================] - 1s 91ms/step - loss: 1.4197e-06 - accuracy: 1.0000 - val_loss: 2.1698 - val_accuracy: 0.7391\nEpoch 194/500\n6/6 [==============================] - 1s 95ms/step - loss: 1.3863e-06 - accuracy: 1.0000 - val_loss: 2.2299 - val_accuracy: 0.7283\nEpoch 195/500\n6/6 [==============================] - 1s 97ms/step - loss: 1.3590e-06 - accuracy: 1.0000 - val_loss: 2.1612 - val_accuracy: 0.7391\nEpoch 196/500\n6/6 [==============================] - 1s 91ms/step - loss: 1.4747e-06 - accuracy: 1.0000 - val_loss: 2.1631 - val_accuracy: 0.7391\nEpoch 197/500\n6/6 [==============================] - 1s 111ms/step - loss: 1.5692e-06 - accuracy: 1.0000 - val_loss: 2.3122 - val_accuracy: 0.7283\nEpoch 198/500\n6/6 [==============================] - 1s 89ms/step - loss: 1.4990e-06 - accuracy: 1.0000 - val_loss: 2.1685 - val_accuracy: 0.7391\nEpoch 199/500\n6/6 [==============================] - 1s 92ms/step - loss: 1.3937e-06 - accuracy: 1.0000 - val_loss: 2.2269 - val_accuracy: 0.7283\nEpoch 200/500\n6/6 [==============================] - 1s 95ms/step - loss: 1.2224e-06 - accuracy: 1.0000 - val_loss: 2.1886 - val_accuracy: 0.7391\nEpoch 201/500\n6/6 [==============================] - 1s 94ms/step - loss: 1.1362e-06 - accuracy: 1.0000 - val_loss: 2.2592 - val_accuracy: 0.7283\nEpoch 202/500\n6/6 [==============================] - 1s 95ms/step - loss: 1.1617e-06 - accuracy: 1.0000 - val_loss: 2.1583 - val_accuracy: 0.7500\nEpoch 203/500\n6/6 [==============================] - 1s 93ms/step - loss: 1.2120e-06 - accuracy: 1.0000 - val_loss: 2.2799 - val_accuracy: 0.7283\nEpoch 204/500\n6/6 [==============================] - 1s 91ms/step - loss: 1.1895e-06 - accuracy: 1.0000 - val_loss: 2.2075 - val_accuracy: 0.7391\nEpoch 205/500\n6/6 [==============================] - 1s 96ms/step - loss: 1.1262e-06 - accuracy: 1.0000 - val_loss: 2.2452 - val_accuracy: 0.7283\nEpoch 206/500\n6/6 [==============================] - 1s 96ms/step - loss: 1.0820e-06 - accuracy: 1.0000 - val_loss: 2.2235 - val_accuracy: 0.7391\nEpoch 207/500\n6/6 [==============================] - 1s 96ms/step - loss: 1.0187e-06 - accuracy: 1.0000 - val_loss: 2.2546 - val_accuracy: 0.7283\nEpoch 208/500\n6/6 [==============================] - 1s 94ms/step - loss: 9.8965e-07 - accuracy: 1.0000 - val_loss: 2.2238 - val_accuracy: 0.7391\nEpoch 209/500\n6/6 [==============================] - 1s 93ms/step - loss: 9.7838e-07 - accuracy: 1.0000 - val_loss: 2.2696 - val_accuracy: 0.7283\nEpoch 210/500\n6/6 [==============================] - 1s 95ms/step - loss: 9.6191e-07 - accuracy: 1.0000 - val_loss: 2.2387 - val_accuracy: 0.7283\nEpoch 211/500\n6/6 [==============================] - 1s 94ms/step - loss: 9.1683e-07 - accuracy: 1.0000 - val_loss: 2.2423 - val_accuracy: 0.7391\nEpoch 212/500\n6/6 [==============================] - 1s 94ms/step - loss: 9.0989e-07 - accuracy: 1.0000 - val_loss: 2.2656 - val_accuracy: 0.7283\nEpoch 213/500\n6/6 [==============================] - 1s 94ms/step - loss: 8.9645e-07 - accuracy: 1.0000 - val_loss: 2.2256 - val_accuracy: 0.7391\nEpoch 214/500\n6/6 [==============================] - 1s 113ms/step - loss: 9.0599e-07 - accuracy: 1.0000 - val_loss: 2.2437 - val_accuracy: 0.7391\nEpoch 215/500\n6/6 [==============================] - 1s 94ms/step - loss: 9.1336e-07 - accuracy: 1.0000 - val_loss: 2.2596 - val_accuracy: 0.7283\nEpoch 216/500\n6/6 [==============================] - 1s 92ms/step - loss: 8.5701e-07 - accuracy: 1.0000 - val_loss: 2.2635 - val_accuracy: 0.7283\nEpoch 217/500\n6/6 [==============================] - 1s 98ms/step - loss: 8.4747e-07 - accuracy: 1.0000 - val_loss: 2.2564 - val_accuracy: 0.7391\nEpoch 218/500\n6/6 [==============================] - 1s 93ms/step - loss: 8.3143e-07 - accuracy: 1.0000 - val_loss: 2.2582 - val_accuracy: 0.7391\nEpoch 219/500\n6/6 [==============================] - 1s 92ms/step - loss: 8.3793e-07 - accuracy: 1.0000 - val_loss: 2.3144 - val_accuracy: 0.7283\nEpoch 220/500\n6/6 [==============================] - 1s 96ms/step - loss: 8.6091e-07 - accuracy: 1.0000 - val_loss: 2.2328 - val_accuracy: 0.7391\nEpoch 221/500\n6/6 [==============================] - 1s 89ms/step - loss: 7.9502e-07 - accuracy: 1.0000 - val_loss: 2.3133 - val_accuracy: 0.7283\nEpoch 222/500\n6/6 [==============================] - 1s 91ms/step - loss: 7.7508e-07 - accuracy: 1.0000 - val_loss: 2.2792 - val_accuracy: 0.7283\nEpoch 223/500\n6/6 [==============================] - 1s 92ms/step - loss: 7.4343e-07 - accuracy: 1.0000 - val_loss: 2.2546 - val_accuracy: 0.7283\nEpoch 224/500\n6/6 [==============================] - 1s 94ms/step - loss: 7.3563e-07 - accuracy: 1.0000 - val_loss: 2.3185 - val_accuracy: 0.7283\nEpoch 225/500\n6/6 [==============================] - 1s 91ms/step - loss: 7.1049e-07 - accuracy: 1.0000 - val_loss: 2.2703 - val_accuracy: 0.7283\nEpoch 226/500\n6/6 [==============================] - 1s 92ms/step - loss: 7.3043e-07 - accuracy: 1.0000 - val_loss: 2.3051 - val_accuracy: 0.7283\nEpoch 227/500\n","name":"stdout"},{"output_type":"stream","text":"6/6 [==============================] - 1s 94ms/step - loss: 7.0528e-07 - accuracy: 1.0000 - val_loss: 2.3277 - val_accuracy: 0.7283\nEpoch 228/500\n6/6 [==============================] - 1s 94ms/step - loss: 6.8448e-07 - accuracy: 1.0000 - val_loss: 2.2722 - val_accuracy: 0.7391\nEpoch 229/500\n6/6 [==============================] - 1s 91ms/step - loss: 6.7798e-07 - accuracy: 1.0000 - val_loss: 2.3101 - val_accuracy: 0.7283\nEpoch 230/500\n6/6 [==============================] - 1s 92ms/step - loss: 6.5630e-07 - accuracy: 1.0000 - val_loss: 2.3181 - val_accuracy: 0.7283\nEpoch 231/500\n6/6 [==============================] - 1s 110ms/step - loss: 6.8361e-07 - accuracy: 1.0000 - val_loss: 2.2932 - val_accuracy: 0.7391\nEpoch 232/500\n6/6 [==============================] - 1s 94ms/step - loss: 7.0268e-07 - accuracy: 1.0000 - val_loss: 2.2959 - val_accuracy: 0.7283\nEpoch 233/500\n6/6 [==============================] - 1s 102ms/step - loss: 6.8751e-07 - accuracy: 1.0000 - val_loss: 2.4047 - val_accuracy: 0.7283\nEpoch 234/500\n6/6 [==============================] - 1s 96ms/step - loss: 6.8231e-07 - accuracy: 1.0000 - val_loss: 2.2521 - val_accuracy: 0.7391\nEpoch 235/500\n6/6 [==============================] - 1s 91ms/step - loss: 6.3116e-07 - accuracy: 1.0000 - val_loss: 2.3698 - val_accuracy: 0.7283\nEpoch 236/500\n6/6 [==============================] - 1s 91ms/step - loss: 6.0905e-07 - accuracy: 1.0000 - val_loss: 2.2828 - val_accuracy: 0.7283\nEpoch 237/500\n6/6 [==============================] - 1s 95ms/step - loss: 6.0125e-07 - accuracy: 1.0000 - val_loss: 2.3616 - val_accuracy: 0.7283\nEpoch 238/500\n6/6 [==============================] - 1s 93ms/step - loss: 5.6700e-07 - accuracy: 1.0000 - val_loss: 2.2846 - val_accuracy: 0.7391\nEpoch 239/500\n6/6 [==============================] - 1s 91ms/step - loss: 5.7697e-07 - accuracy: 1.0000 - val_loss: 2.3432 - val_accuracy: 0.7283\nEpoch 240/500\n6/6 [==============================] - 1s 94ms/step - loss: 5.3796e-07 - accuracy: 1.0000 - val_loss: 2.3054 - val_accuracy: 0.7391\nEpoch 241/500\n6/6 [==============================] - 1s 93ms/step - loss: 5.2452e-07 - accuracy: 1.0000 - val_loss: 2.3487 - val_accuracy: 0.7283\nEpoch 242/500\n6/6 [==============================] - 1s 96ms/step - loss: 5.2062e-07 - accuracy: 1.0000 - val_loss: 2.3037 - val_accuracy: 0.7391\nEpoch 243/500\n6/6 [==============================] - 1s 148ms/step - loss: 5.1889e-07 - accuracy: 1.0000 - val_loss: 2.3757 - val_accuracy: 0.7283\nEpoch 244/500\n6/6 [==============================] - 1s 92ms/step - loss: 5.2235e-07 - accuracy: 1.0000 - val_loss: 2.2798 - val_accuracy: 0.7391\nEpoch 245/500\n6/6 [==============================] - 1s 92ms/step - loss: 5.0241e-07 - accuracy: 1.0000 - val_loss: 2.3858 - val_accuracy: 0.7283\nEpoch 246/500\n6/6 [==============================] - 1s 95ms/step - loss: 4.9114e-07 - accuracy: 1.0000 - val_loss: 2.2891 - val_accuracy: 0.7391\nEpoch 247/500\n6/6 [==============================] - 1s 158ms/step - loss: 5.0891e-07 - accuracy: 1.0000 - val_loss: 2.3260 - val_accuracy: 0.7391\nEpoch 248/500\n6/6 [==============================] - 1s 98ms/step - loss: 5.0025e-07 - accuracy: 1.0000 - val_loss: 2.3760 - val_accuracy: 0.7283\nEpoch 249/500\n6/6 [==============================] - 1s 96ms/step - loss: 4.8637e-07 - accuracy: 1.0000 - val_loss: 2.3125 - val_accuracy: 0.7283\nEpoch 250/500\n6/6 [==============================] - 1s 95ms/step - loss: 4.6036e-07 - accuracy: 1.0000 - val_loss: 2.3795 - val_accuracy: 0.7283\nEpoch 251/500\n6/6 [==============================] - 1s 98ms/step - loss: 4.4866e-07 - accuracy: 1.0000 - val_loss: 2.3480 - val_accuracy: 0.7283\nEpoch 252/500\n6/6 [==============================] - 1s 100ms/step - loss: 4.4606e-07 - accuracy: 1.0000 - val_loss: 2.3694 - val_accuracy: 0.7283\nEpoch 253/500\n6/6 [==============================] - 1s 94ms/step - loss: 4.4779e-07 - accuracy: 1.0000 - val_loss: 2.3554 - val_accuracy: 0.7174\nEpoch 254/500\n6/6 [==============================] - 1s 103ms/step - loss: 4.3349e-07 - accuracy: 1.0000 - val_loss: 2.3331 - val_accuracy: 0.7283\nEpoch 255/500\n6/6 [==============================] - 1s 106ms/step - loss: 4.2395e-07 - accuracy: 1.0000 - val_loss: 2.4249 - val_accuracy: 0.7283\nEpoch 256/500\n6/6 [==============================] - 1s 94ms/step - loss: 4.5473e-07 - accuracy: 1.0000 - val_loss: 2.2945 - val_accuracy: 0.7391\nEpoch 257/500\n6/6 [==============================] - 1s 96ms/step - loss: 4.3912e-07 - accuracy: 1.0000 - val_loss: 2.4144 - val_accuracy: 0.7283\nEpoch 258/500\n6/6 [==============================] - 1s 94ms/step - loss: 4.3045e-07 - accuracy: 1.0000 - val_loss: 2.3722 - val_accuracy: 0.7283\nEpoch 259/500\n6/6 [==============================] - 1s 93ms/step - loss: 4.2829e-07 - accuracy: 1.0000 - val_loss: 2.3249 - val_accuracy: 0.7391\nEpoch 260/500\n6/6 [==============================] - 1s 91ms/step - loss: 3.9577e-07 - accuracy: 1.0000 - val_loss: 2.3702 - val_accuracy: 0.7283\nEpoch 261/500\n6/6 [==============================] - 1s 99ms/step - loss: 3.8884e-07 - accuracy: 1.0000 - val_loss: 2.4111 - val_accuracy: 0.7283\nEpoch 262/500\n6/6 [==============================] - 1s 101ms/step - loss: 3.8407e-07 - accuracy: 1.0000 - val_loss: 2.3508 - val_accuracy: 0.7283\nEpoch 263/500\n6/6 [==============================] - 1s 117ms/step - loss: 3.6370e-07 - accuracy: 1.0000 - val_loss: 2.3871 - val_accuracy: 0.7283\nEpoch 264/500\n6/6 [==============================] - 1s 102ms/step - loss: 3.6586e-07 - accuracy: 1.0000 - val_loss: 2.3743 - val_accuracy: 0.7283\nEpoch 265/500\n6/6 [==============================] - 1s 91ms/step - loss: 3.6110e-07 - accuracy: 1.0000 - val_loss: 2.3453 - val_accuracy: 0.7283\nEpoch 266/500\n6/6 [==============================] - 1s 93ms/step - loss: 3.7497e-07 - accuracy: 1.0000 - val_loss: 2.4435 - val_accuracy: 0.7283\nEpoch 267/500\n6/6 [==============================] - 1s 92ms/step - loss: 3.6153e-07 - accuracy: 1.0000 - val_loss: 2.3246 - val_accuracy: 0.7391\nEpoch 268/500\n6/6 [==============================] - 1s 92ms/step - loss: 3.6023e-07 - accuracy: 1.0000 - val_loss: 2.4263 - val_accuracy: 0.7283\nEpoch 269/500\n6/6 [==============================] - 1s 95ms/step - loss: 3.4116e-07 - accuracy: 1.0000 - val_loss: 2.3632 - val_accuracy: 0.7283\nEpoch 270/500\n6/6 [==============================] - 1s 92ms/step - loss: 3.5936e-07 - accuracy: 1.0000 - val_loss: 2.3546 - val_accuracy: 0.7283\nEpoch 271/500\n6/6 [==============================] - 1s 99ms/step - loss: 3.3595e-07 - accuracy: 1.0000 - val_loss: 2.4209 - val_accuracy: 0.7283\nEpoch 272/500\n6/6 [==============================] - 1s 90ms/step - loss: 3.2815e-07 - accuracy: 1.0000 - val_loss: 2.3827 - val_accuracy: 0.7283\nEpoch 273/500\n6/6 [==============================] - 1s 93ms/step - loss: 3.2078e-07 - accuracy: 1.0000 - val_loss: 2.3799 - val_accuracy: 0.7283\nEpoch 274/500\n6/6 [==============================] - 1s 98ms/step - loss: 3.1601e-07 - accuracy: 1.0000 - val_loss: 2.4068 - val_accuracy: 0.7283\nEpoch 275/500\n6/6 [==============================] - 1s 91ms/step - loss: 3.2598e-07 - accuracy: 1.0000 - val_loss: 2.4437 - val_accuracy: 0.7283\nEpoch 276/500\n6/6 [==============================] - 1s 89ms/step - loss: 3.1341e-07 - accuracy: 1.0000 - val_loss: 2.3712 - val_accuracy: 0.7283\nEpoch 277/500\n6/6 [==============================] - 1s 96ms/step - loss: 2.9781e-07 - accuracy: 1.0000 - val_loss: 2.4188 - val_accuracy: 0.7283\nEpoch 278/500\n6/6 [==============================] - 1s 93ms/step - loss: 3.0344e-07 - accuracy: 1.0000 - val_loss: 2.3866 - val_accuracy: 0.7283\nEpoch 279/500\n6/6 [==============================] - 1s 95ms/step - loss: 2.9304e-07 - accuracy: 1.0000 - val_loss: 2.4136 - val_accuracy: 0.7283\nEpoch 280/500\n6/6 [==============================] - 1s 111ms/step - loss: 2.9434e-07 - accuracy: 1.0000 - val_loss: 2.3981 - val_accuracy: 0.7283\nEpoch 281/500\n6/6 [==============================] - 1s 99ms/step - loss: 2.8047e-07 - accuracy: 1.0000 - val_loss: 2.4312 - val_accuracy: 0.7283\nEpoch 282/500\n6/6 [==============================] - 1s 91ms/step - loss: 2.9390e-07 - accuracy: 1.0000 - val_loss: 2.3889 - val_accuracy: 0.7283\nEpoch 283/500\n","name":"stdout"},{"output_type":"stream","text":"6/6 [==============================] - 1s 94ms/step - loss: 2.8914e-07 - accuracy: 1.0000 - val_loss: 2.4295 - val_accuracy: 0.7174\nEpoch 284/500\n6/6 [==============================] - 1s 93ms/step - loss: 2.9867e-07 - accuracy: 1.0000 - val_loss: 2.4198 - val_accuracy: 0.7283\nEpoch 285/500\n6/6 [==============================] - 1s 92ms/step - loss: 2.8090e-07 - accuracy: 1.0000 - val_loss: 2.4149 - val_accuracy: 0.7283\nEpoch 286/500\n6/6 [==============================] - 1s 94ms/step - loss: 2.6963e-07 - accuracy: 1.0000 - val_loss: 2.4392 - val_accuracy: 0.7283\nEpoch 287/500\n6/6 [==============================] - 1s 94ms/step - loss: 2.6356e-07 - accuracy: 1.0000 - val_loss: 2.3754 - val_accuracy: 0.7391\nEpoch 288/500\n6/6 [==============================] - 1s 94ms/step - loss: 2.6790e-07 - accuracy: 1.0000 - val_loss: 2.4786 - val_accuracy: 0.7283\nEpoch 289/500\n6/6 [==============================] - 1s 96ms/step - loss: 2.7787e-07 - accuracy: 1.0000 - val_loss: 2.3949 - val_accuracy: 0.7283\nEpoch 290/500\n6/6 [==============================] - 1s 98ms/step - loss: 2.6573e-07 - accuracy: 1.0000 - val_loss: 2.4278 - val_accuracy: 0.7174\nEpoch 291/500\n6/6 [==============================] - 1s 98ms/step - loss: 2.5923e-07 - accuracy: 1.0000 - val_loss: 2.4086 - val_accuracy: 0.7391\nEpoch 292/500\n6/6 [==============================] - 1s 94ms/step - loss: 2.6616e-07 - accuracy: 1.0000 - val_loss: 2.4456 - val_accuracy: 0.7174\nEpoch 293/500\n6/6 [==============================] - 1s 89ms/step - loss: 2.7180e-07 - accuracy: 1.0000 - val_loss: 2.3866 - val_accuracy: 0.7500\nEpoch 294/500\n6/6 [==============================] - 1s 93ms/step - loss: 2.5923e-07 - accuracy: 1.0000 - val_loss: 2.5245 - val_accuracy: 0.7174\nEpoch 295/500\n6/6 [==============================] - 1s 92ms/step - loss: 2.6660e-07 - accuracy: 1.0000 - val_loss: 2.3780 - val_accuracy: 0.7391\nEpoch 296/500\n6/6 [==============================] - 1s 102ms/step - loss: 2.4622e-07 - accuracy: 1.0000 - val_loss: 2.4608 - val_accuracy: 0.7174\nEpoch 297/500\n6/6 [==============================] - 1s 104ms/step - loss: 2.4189e-07 - accuracy: 1.0000 - val_loss: 2.4055 - val_accuracy: 0.7283\nEpoch 298/500\n6/6 [==============================] - 1s 94ms/step - loss: 2.2932e-07 - accuracy: 1.0000 - val_loss: 2.4779 - val_accuracy: 0.7283\nEpoch 299/500\n6/6 [==============================] - 1s 99ms/step - loss: 2.2325e-07 - accuracy: 1.0000 - val_loss: 2.4271 - val_accuracy: 0.7283\nEpoch 300/500\n6/6 [==============================] - 1s 93ms/step - loss: 2.2455e-07 - accuracy: 1.0000 - val_loss: 2.4241 - val_accuracy: 0.7283\nEpoch 301/500\n6/6 [==============================] - 1s 93ms/step - loss: 2.2541e-07 - accuracy: 1.0000 - val_loss: 2.4740 - val_accuracy: 0.7283\nEpoch 302/500\n6/6 [==============================] - 1s 89ms/step - loss: 2.2671e-07 - accuracy: 1.0000 - val_loss: 2.4093 - val_accuracy: 0.7391\nEpoch 303/500\n6/6 [==============================] - 1s 97ms/step - loss: 2.2151e-07 - accuracy: 1.0000 - val_loss: 2.4409 - val_accuracy: 0.7283\nEpoch 304/500\n6/6 [==============================] - 1s 95ms/step - loss: 2.2281e-07 - accuracy: 1.0000 - val_loss: 2.5100 - val_accuracy: 0.7283\nEpoch 305/500\n6/6 [==============================] - 1s 95ms/step - loss: 2.3625e-07 - accuracy: 1.0000 - val_loss: 2.3486 - val_accuracy: 0.7391\nEpoch 306/500\n6/6 [==============================] - 1s 92ms/step - loss: 2.4579e-07 - accuracy: 1.0000 - val_loss: 2.4921 - val_accuracy: 0.7174\nEpoch 307/500\n6/6 [==============================] - 1s 94ms/step - loss: 2.2368e-07 - accuracy: 1.0000 - val_loss: 2.4929 - val_accuracy: 0.7283\nEpoch 308/500\n6/6 [==============================] - 1s 97ms/step - loss: 2.1458e-07 - accuracy: 1.0000 - val_loss: 2.4061 - val_accuracy: 0.7391\nEpoch 309/500\n6/6 [==============================] - 1s 93ms/step - loss: 2.1241e-07 - accuracy: 1.0000 - val_loss: 2.5184 - val_accuracy: 0.7283\nEpoch 310/500\n6/6 [==============================] - 1s 95ms/step - loss: 2.0157e-07 - accuracy: 1.0000 - val_loss: 2.4085 - val_accuracy: 0.7391\nEpoch 311/500\n6/6 [==============================] - 1s 98ms/step - loss: 2.0244e-07 - accuracy: 1.0000 - val_loss: 2.4316 - val_accuracy: 0.7283\nEpoch 312/500\n6/6 [==============================] - 1s 103ms/step - loss: 2.0201e-07 - accuracy: 1.0000 - val_loss: 2.5296 - val_accuracy: 0.7283\nEpoch 313/500\n6/6 [==============================] - 1s 109ms/step - loss: 2.0634e-07 - accuracy: 1.0000 - val_loss: 2.4228 - val_accuracy: 0.7391\nEpoch 314/500\n6/6 [==============================] - 1s 92ms/step - loss: 1.9204e-07 - accuracy: 1.0000 - val_loss: 2.4942 - val_accuracy: 0.7283\nEpoch 315/500\n6/6 [==============================] - 1s 90ms/step - loss: 2.0201e-07 - accuracy: 1.0000 - val_loss: 2.4906 - val_accuracy: 0.7283\nEpoch 316/500\n6/6 [==============================] - 1s 92ms/step - loss: 1.8467e-07 - accuracy: 1.0000 - val_loss: 2.4136 - val_accuracy: 0.7391\nEpoch 317/500\n6/6 [==============================] - 1s 95ms/step - loss: 1.9030e-07 - accuracy: 1.0000 - val_loss: 2.4850 - val_accuracy: 0.7174\nEpoch 318/500\n6/6 [==============================] - 1s 99ms/step - loss: 1.8163e-07 - accuracy: 1.0000 - val_loss: 2.4926 - val_accuracy: 0.7174\nEpoch 319/500\n6/6 [==============================] - 1s 91ms/step - loss: 1.7643e-07 - accuracy: 1.0000 - val_loss: 2.4249 - val_accuracy: 0.7391\nEpoch 320/500\n6/6 [==============================] - 1s 94ms/step - loss: 1.7816e-07 - accuracy: 1.0000 - val_loss: 2.5226 - val_accuracy: 0.7174\nEpoch 321/500\n6/6 [==============================] - 1s 93ms/step - loss: 1.8380e-07 - accuracy: 1.0000 - val_loss: 2.4237 - val_accuracy: 0.7391\nEpoch 322/500\n6/6 [==============================] - 1s 94ms/step - loss: 1.6906e-07 - accuracy: 1.0000 - val_loss: 2.4975 - val_accuracy: 0.7174\nEpoch 323/500\n6/6 [==============================] - 1s 93ms/step - loss: 1.6993e-07 - accuracy: 1.0000 - val_loss: 2.4926 - val_accuracy: 0.7174\nEpoch 324/500\n6/6 [==============================] - 1s 92ms/step - loss: 1.6949e-07 - accuracy: 1.0000 - val_loss: 2.5115 - val_accuracy: 0.7283\nEpoch 325/500\n6/6 [==============================] - 1s 95ms/step - loss: 1.6776e-07 - accuracy: 1.0000 - val_loss: 2.4324 - val_accuracy: 0.7391\nEpoch 326/500\n6/6 [==============================] - 1s 96ms/step - loss: 1.8510e-07 - accuracy: 1.0000 - val_loss: 2.3826 - val_accuracy: 0.7391\nEpoch 327/500\n6/6 [==============================] - 1s 98ms/step - loss: 2.0851e-07 - accuracy: 1.0000 - val_loss: 2.6041 - val_accuracy: 0.7283\nEpoch 328/500\n6/6 [==============================] - 1s 97ms/step - loss: 1.8033e-07 - accuracy: 1.0000 - val_loss: 2.4569 - val_accuracy: 0.7391\nEpoch 329/500\n6/6 [==============================] - 1s 94ms/step - loss: 1.6082e-07 - accuracy: 1.0000 - val_loss: 2.4947 - val_accuracy: 0.7174\nEpoch 330/500\n6/6 [==============================] - 1s 107ms/step - loss: 1.5649e-07 - accuracy: 1.0000 - val_loss: 2.5288 - val_accuracy: 0.7283\nEpoch 331/500\n6/6 [==============================] - 1s 93ms/step - loss: 1.6082e-07 - accuracy: 1.0000 - val_loss: 2.4313 - val_accuracy: 0.7391\nEpoch 332/500\n6/6 [==============================] - 1s 94ms/step - loss: 1.7946e-07 - accuracy: 1.0000 - val_loss: 2.5301 - val_accuracy: 0.7283\nEpoch 333/500\n6/6 [==============================] - 1s 95ms/step - loss: 1.5606e-07 - accuracy: 1.0000 - val_loss: 2.5086 - val_accuracy: 0.7174\nEpoch 334/500\n6/6 [==============================] - 1s 90ms/step - loss: 1.5476e-07 - accuracy: 1.0000 - val_loss: 2.4235 - val_accuracy: 0.7391\nEpoch 335/500\n6/6 [==============================] - 1s 93ms/step - loss: 1.5345e-07 - accuracy: 1.0000 - val_loss: 2.5884 - val_accuracy: 0.7174\nEpoch 336/500\n6/6 [==============================] - 1s 93ms/step - loss: 1.5649e-07 - accuracy: 1.0000 - val_loss: 2.4170 - val_accuracy: 0.7391\nEpoch 337/500\n6/6 [==============================] - 1s 123ms/step - loss: 1.4348e-07 - accuracy: 1.0000 - val_loss: 2.5698 - val_accuracy: 0.7174\nEpoch 338/500\n6/6 [==============================] - 1s 100ms/step - loss: 1.5519e-07 - accuracy: 1.0000 - val_loss: 2.4720 - val_accuracy: 0.7391\nEpoch 339/500\n","name":"stdout"},{"output_type":"stream","text":"6/6 [==============================] - 1s 94ms/step - loss: 1.5042e-07 - accuracy: 1.0000 - val_loss: 2.4463 - val_accuracy: 0.7391\nEpoch 340/500\n6/6 [==============================] - 1s 97ms/step - loss: 1.4652e-07 - accuracy: 1.0000 - val_loss: 2.5631 - val_accuracy: 0.7283\nEpoch 341/500\n6/6 [==============================] - 1s 95ms/step - loss: 1.4045e-07 - accuracy: 1.0000 - val_loss: 2.4948 - val_accuracy: 0.7283\nEpoch 342/500\n6/6 [==============================] - 1s 94ms/step - loss: 1.4045e-07 - accuracy: 1.0000 - val_loss: 2.4720 - val_accuracy: 0.7391\nEpoch 343/500\n6/6 [==============================] - 1s 93ms/step - loss: 1.3742e-07 - accuracy: 1.0000 - val_loss: 2.5403 - val_accuracy: 0.7174\nEpoch 344/500\n6/6 [==============================] - 1s 92ms/step - loss: 1.4435e-07 - accuracy: 1.0000 - val_loss: 2.5576 - val_accuracy: 0.7283\nEpoch 345/500\n6/6 [==============================] - 1s 110ms/step - loss: 1.4218e-07 - accuracy: 1.0000 - val_loss: 2.4968 - val_accuracy: 0.7391\nEpoch 346/500\n6/6 [==============================] - 1s 123ms/step - loss: 1.3785e-07 - accuracy: 1.0000 - val_loss: 2.4821 - val_accuracy: 0.7391\nEpoch 347/500\n6/6 [==============================] - 1s 96ms/step - loss: 1.3308e-07 - accuracy: 1.0000 - val_loss: 2.5769 - val_accuracy: 0.7174\nEpoch 348/500\n6/6 [==============================] - 1s 94ms/step - loss: 1.5085e-07 - accuracy: 1.0000 - val_loss: 2.5150 - val_accuracy: 0.7391\nEpoch 349/500\n6/6 [==============================] - 1s 98ms/step - loss: 1.3828e-07 - accuracy: 1.0000 - val_loss: 2.5317 - val_accuracy: 0.7174\nEpoch 350/500\n6/6 [==============================] - 1s 96ms/step - loss: 1.4392e-07 - accuracy: 1.0000 - val_loss: 2.4794 - val_accuracy: 0.7391\nEpoch 351/500\n6/6 [==============================] - 1s 94ms/step - loss: 1.3005e-07 - accuracy: 1.0000 - val_loss: 2.5738 - val_accuracy: 0.7174\nEpoch 352/500\n6/6 [==============================] - 1s 93ms/step - loss: 1.1748e-07 - accuracy: 1.0000 - val_loss: 2.4522 - val_accuracy: 0.7391\nEpoch 353/500\n6/6 [==============================] - 1s 94ms/step - loss: 1.2788e-07 - accuracy: 1.0000 - val_loss: 2.5904 - val_accuracy: 0.7283\nEpoch 354/500\n6/6 [==============================] - 1s 91ms/step - loss: 1.3221e-07 - accuracy: 1.0000 - val_loss: 2.5097 - val_accuracy: 0.7283\nEpoch 355/500\n6/6 [==============================] - 1s 97ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 2.5529 - val_accuracy: 0.7174\nEpoch 356/500\n6/6 [==============================] - 1s 99ms/step - loss: 1.3351e-07 - accuracy: 1.0000 - val_loss: 2.5029 - val_accuracy: 0.7500\nEpoch 357/500\n6/6 [==============================] - 1s 94ms/step - loss: 1.1834e-07 - accuracy: 1.0000 - val_loss: 2.5647 - val_accuracy: 0.7174\nEpoch 358/500\n6/6 [==============================] - 1s 94ms/step - loss: 1.2354e-07 - accuracy: 1.0000 - val_loss: 2.5488 - val_accuracy: 0.7283\nEpoch 359/500\n6/6 [==============================] - 1s 104ms/step - loss: 1.2571e-07 - accuracy: 1.0000 - val_loss: 2.5887 - val_accuracy: 0.7283\nEpoch 360/500\n6/6 [==============================] - 1s 93ms/step - loss: 1.1184e-07 - accuracy: 1.0000 - val_loss: 2.4324 - val_accuracy: 0.7391\nEpoch 361/500\n6/6 [==============================] - 1s 93ms/step - loss: 1.2615e-07 - accuracy: 1.0000 - val_loss: 2.5532 - val_accuracy: 0.7283\nEpoch 362/500\n6/6 [==============================] - 1s 96ms/step - loss: 1.2571e-07 - accuracy: 1.0000 - val_loss: 2.5388 - val_accuracy: 0.7283\nEpoch 363/500\n6/6 [==============================] - 1s 110ms/step - loss: 1.0967e-07 - accuracy: 1.0000 - val_loss: 2.5188 - val_accuracy: 0.7500\nEpoch 364/500\n6/6 [==============================] - 1s 97ms/step - loss: 1.2008e-07 - accuracy: 1.0000 - val_loss: 2.5422 - val_accuracy: 0.7283\nEpoch 365/500\n6/6 [==============================] - 1s 97ms/step - loss: 1.0144e-07 - accuracy: 1.0000 - val_loss: 2.5622 - val_accuracy: 0.7283\nEpoch 366/500\n6/6 [==============================] - 1s 95ms/step - loss: 1.0794e-07 - accuracy: 1.0000 - val_loss: 2.4750 - val_accuracy: 0.7391\nEpoch 367/500\n6/6 [==============================] - 1s 94ms/step - loss: 1.0447e-07 - accuracy: 1.0000 - val_loss: 2.6124 - val_accuracy: 0.7283\nEpoch 368/500\n6/6 [==============================] - 1s 92ms/step - loss: 1.1487e-07 - accuracy: 1.0000 - val_loss: 2.5522 - val_accuracy: 0.7174\nEpoch 369/500\n6/6 [==============================] - 1s 93ms/step - loss: 1.0144e-07 - accuracy: 1.0000 - val_loss: 2.5532 - val_accuracy: 0.7283\nEpoch 370/500\n6/6 [==============================] - 1s 94ms/step - loss: 1.0144e-07 - accuracy: 1.0000 - val_loss: 2.5948 - val_accuracy: 0.7174\nEpoch 371/500\n6/6 [==============================] - 1s 91ms/step - loss: 9.8835e-08 - accuracy: 1.0000 - val_loss: 2.5615 - val_accuracy: 0.7174\nEpoch 372/500\n6/6 [==============================] - 1s 94ms/step - loss: 9.4500e-08 - accuracy: 1.0000 - val_loss: 2.5197 - val_accuracy: 0.7391\nEpoch 373/500\n6/6 [==============================] - 1s 94ms/step - loss: 1.0144e-07 - accuracy: 1.0000 - val_loss: 2.5586 - val_accuracy: 0.7174\nEpoch 374/500\n6/6 [==============================] - 1s 99ms/step - loss: 9.9702e-08 - accuracy: 1.0000 - val_loss: 2.5318 - val_accuracy: 0.7391\nEpoch 375/500\n6/6 [==============================] - 1s 93ms/step - loss: 9.5367e-08 - accuracy: 1.0000 - val_loss: 2.5930 - val_accuracy: 0.7174\nEpoch 376/500\n6/6 [==============================] - 1s 92ms/step - loss: 1.0014e-07 - accuracy: 1.0000 - val_loss: 2.5371 - val_accuracy: 0.7391\nEpoch 377/500\n6/6 [==============================] - 1s 94ms/step - loss: 9.3633e-08 - accuracy: 1.0000 - val_loss: 2.5401 - val_accuracy: 0.7391\nEpoch 378/500\n6/6 [==============================] - 1s 108ms/step - loss: 8.8432e-08 - accuracy: 1.0000 - val_loss: 2.6065 - val_accuracy: 0.7174\nEpoch 379/500\n6/6 [==============================] - 1s 108ms/step - loss: 9.4067e-08 - accuracy: 1.0000 - val_loss: 2.5081 - val_accuracy: 0.7391\nEpoch 380/500\n6/6 [==============================] - 1s 97ms/step - loss: 9.0166e-08 - accuracy: 1.0000 - val_loss: 2.5674 - val_accuracy: 0.7283\nEpoch 381/500\n6/6 [==============================] - 1s 95ms/step - loss: 9.0166e-08 - accuracy: 1.0000 - val_loss: 2.5847 - val_accuracy: 0.7283\nEpoch 382/500\n6/6 [==============================] - 1s 93ms/step - loss: 8.6264e-08 - accuracy: 1.0000 - val_loss: 2.5354 - val_accuracy: 0.7391\nEpoch 383/500\n6/6 [==============================] - 1s 95ms/step - loss: 8.6698e-08 - accuracy: 1.0000 - val_loss: 2.5182 - val_accuracy: 0.7391\nEpoch 384/500\n6/6 [==============================] - 1s 90ms/step - loss: 9.1033e-08 - accuracy: 1.0000 - val_loss: 2.6393 - val_accuracy: 0.7391\nEpoch 385/500\n6/6 [==============================] - 1s 92ms/step - loss: 8.6264e-08 - accuracy: 1.0000 - val_loss: 2.5451 - val_accuracy: 0.7391\nEpoch 386/500\n6/6 [==============================] - 1s 94ms/step - loss: 8.1929e-08 - accuracy: 1.0000 - val_loss: 2.5882 - val_accuracy: 0.7391\nEpoch 387/500\n6/6 [==============================] - 1s 95ms/step - loss: 8.1062e-08 - accuracy: 1.0000 - val_loss: 2.6025 - val_accuracy: 0.7283\nEpoch 388/500\n6/6 [==============================] - 1s 89ms/step - loss: 7.9328e-08 - accuracy: 1.0000 - val_loss: 2.5456 - val_accuracy: 0.7500\nEpoch 389/500\n6/6 [==============================] - 1s 93ms/step - loss: 8.3663e-08 - accuracy: 1.0000 - val_loss: 2.5028 - val_accuracy: 0.7391\nEpoch 390/500\n6/6 [==============================] - 1s 93ms/step - loss: 9.7101e-08 - accuracy: 1.0000 - val_loss: 2.6599 - val_accuracy: 0.7283\nEpoch 391/500\n6/6 [==============================] - 1s 91ms/step - loss: 7.3693e-08 - accuracy: 1.0000 - val_loss: 2.5695 - val_accuracy: 0.7500\nEpoch 392/500\n6/6 [==============================] - 1s 90ms/step - loss: 7.7594e-08 - accuracy: 1.0000 - val_loss: 2.5795 - val_accuracy: 0.7500\nEpoch 393/500\n6/6 [==============================] - 1s 95ms/step - loss: 7.3693e-08 - accuracy: 1.0000 - val_loss: 2.6045 - val_accuracy: 0.7391\nEpoch 394/500\n6/6 [==============================] - 1s 93ms/step - loss: 7.7161e-08 - accuracy: 1.0000 - val_loss: 2.6183 - val_accuracy: 0.7391\nEpoch 395/500\n","name":"stdout"},{"output_type":"stream","text":"6/6 [==============================] - 1s 92ms/step - loss: 8.1496e-08 - accuracy: 1.0000 - val_loss: 2.6557 - val_accuracy: 0.7283\nEpoch 396/500\n6/6 [==============================] - 1s 102ms/step - loss: 8.1929e-08 - accuracy: 1.0000 - val_loss: 2.4999 - val_accuracy: 0.7391\nEpoch 397/500\n6/6 [==============================] - 1s 99ms/step - loss: 7.8895e-08 - accuracy: 1.0000 - val_loss: 2.5691 - val_accuracy: 0.7500\nEpoch 398/500\n6/6 [==============================] - 1s 93ms/step - loss: 7.2393e-08 - accuracy: 1.0000 - val_loss: 2.6350 - val_accuracy: 0.7391\nEpoch 399/500\n6/6 [==============================] - 1s 92ms/step - loss: 6.5457e-08 - accuracy: 1.0000 - val_loss: 2.5526 - val_accuracy: 0.7500\nEpoch 400/500\n6/6 [==============================] - 1s 94ms/step - loss: 7.1092e-08 - accuracy: 1.0000 - val_loss: 2.6198 - val_accuracy: 0.7391\nEpoch 401/500\n6/6 [==============================] - 1s 90ms/step - loss: 6.5023e-08 - accuracy: 1.0000 - val_loss: 2.5865 - val_accuracy: 0.7500\nEpoch 402/500\n6/6 [==============================] - 1s 101ms/step - loss: 7.2826e-08 - accuracy: 1.0000 - val_loss: 2.6706 - val_accuracy: 0.7391\nEpoch 403/500\n6/6 [==============================] - 1s 94ms/step - loss: 7.7594e-08 - accuracy: 1.0000 - val_loss: 2.6799 - val_accuracy: 0.7283\nEpoch 404/500\n6/6 [==============================] - 1s 99ms/step - loss: 6.3289e-08 - accuracy: 1.0000 - val_loss: 2.5354 - val_accuracy: 0.7500\nEpoch 405/500\n6/6 [==============================] - 1s 92ms/step - loss: 7.2826e-08 - accuracy: 1.0000 - val_loss: 2.5949 - val_accuracy: 0.7500\nEpoch 406/500\n6/6 [==============================] - 1s 94ms/step - loss: 7.0659e-08 - accuracy: 1.0000 - val_loss: 2.5669 - val_accuracy: 0.7500\nEpoch 407/500\n6/6 [==============================] - 1s 89ms/step - loss: 6.2422e-08 - accuracy: 1.0000 - val_loss: 2.6409 - val_accuracy: 0.7391\nEpoch 408/500\n6/6 [==============================] - 1s 104ms/step - loss: 6.5457e-08 - accuracy: 1.0000 - val_loss: 2.6473 - val_accuracy: 0.7391\nEpoch 409/500\n6/6 [==============================] - 1s 92ms/step - loss: 6.8925e-08 - accuracy: 1.0000 - val_loss: 2.5857 - val_accuracy: 0.7500\nEpoch 410/500\n6/6 [==============================] - 1s 96ms/step - loss: 6.1555e-08 - accuracy: 1.0000 - val_loss: 2.5863 - val_accuracy: 0.7500\nEpoch 411/500\n6/6 [==============================] - 1s 92ms/step - loss: 6.4590e-08 - accuracy: 1.0000 - val_loss: 2.6775 - val_accuracy: 0.7283\nEpoch 412/500\n6/6 [==============================] - 1s 98ms/step - loss: 6.2856e-08 - accuracy: 1.0000 - val_loss: 2.6252 - val_accuracy: 0.7609\nEpoch 413/500\n6/6 [==============================] - 1s 113ms/step - loss: 6.3289e-08 - accuracy: 1.0000 - val_loss: 2.6189 - val_accuracy: 0.7500\nEpoch 414/500\n6/6 [==============================] - 1s 94ms/step - loss: 5.6787e-08 - accuracy: 1.0000 - val_loss: 2.6064 - val_accuracy: 0.7500\nEpoch 415/500\n6/6 [==============================] - 1s 92ms/step - loss: 6.0688e-08 - accuracy: 1.0000 - val_loss: 2.6762 - val_accuracy: 0.7391\nEpoch 416/500\n6/6 [==============================] - 1s 93ms/step - loss: 5.3319e-08 - accuracy: 1.0000 - val_loss: 2.5990 - val_accuracy: 0.7500\nEpoch 417/500\n6/6 [==============================] - 1s 98ms/step - loss: 5.6787e-08 - accuracy: 1.0000 - val_loss: 2.6008 - val_accuracy: 0.7500\nEpoch 418/500\n6/6 [==============================] - 1s 95ms/step - loss: 5.8954e-08 - accuracy: 1.0000 - val_loss: 2.6451 - val_accuracy: 0.7500\nEpoch 419/500\n6/6 [==============================] - 1s 90ms/step - loss: 5.0718e-08 - accuracy: 1.0000 - val_loss: 2.6996 - val_accuracy: 0.7391\nEpoch 420/500\n6/6 [==============================] - 1s 93ms/step - loss: 5.5053e-08 - accuracy: 1.0000 - val_loss: 2.6762 - val_accuracy: 0.7500\nEpoch 421/500\n6/6 [==============================] - 1s 100ms/step - loss: 5.8521e-08 - accuracy: 1.0000 - val_loss: 2.6569 - val_accuracy: 0.7500\nEpoch 422/500\n6/6 [==============================] - 1s 91ms/step - loss: 5.6787e-08 - accuracy: 1.0000 - val_loss: 2.6334 - val_accuracy: 0.7500\nEpoch 423/500\n6/6 [==============================] - 1s 95ms/step - loss: 6.1555e-08 - accuracy: 1.0000 - val_loss: 2.6048 - val_accuracy: 0.7500\nEpoch 424/500\n6/6 [==============================] - 1s 98ms/step - loss: 5.2019e-08 - accuracy: 1.0000 - val_loss: 2.7262 - val_accuracy: 0.7391\nEpoch 425/500\n6/6 [==============================] - 1s 91ms/step - loss: 4.7684e-08 - accuracy: 1.0000 - val_loss: 2.7523 - val_accuracy: 0.7391\nEpoch 426/500\n6/6 [==============================] - 1s 93ms/step - loss: 6.2422e-08 - accuracy: 1.0000 - val_loss: 2.7428 - val_accuracy: 0.7391\nEpoch 427/500\n6/6 [==============================] - 1s 95ms/step - loss: 6.8058e-08 - accuracy: 1.0000 - val_loss: 2.6795 - val_accuracy: 0.7391\nEpoch 428/500\n6/6 [==============================] - 1s 115ms/step - loss: 5.2886e-08 - accuracy: 1.0000 - val_loss: 2.5342 - val_accuracy: 0.7283\nEpoch 429/500\n6/6 [==============================] - 1s 107ms/step - loss: 5.4186e-08 - accuracy: 1.0000 - val_loss: 2.6096 - val_accuracy: 0.7500\nEpoch 430/500\n6/6 [==============================] - 1s 110ms/step - loss: 4.7684e-08 - accuracy: 1.0000 - val_loss: 2.6264 - val_accuracy: 0.7500\nEpoch 431/500\n6/6 [==============================] - 1s 94ms/step - loss: 4.2915e-08 - accuracy: 1.0000 - val_loss: 2.7509 - val_accuracy: 0.7391\nEpoch 432/500\n6/6 [==============================] - 1s 92ms/step - loss: 5.2886e-08 - accuracy: 1.0000 - val_loss: 2.7898 - val_accuracy: 0.7391\nEpoch 433/500\n6/6 [==============================] - 1s 91ms/step - loss: 5.3753e-08 - accuracy: 1.0000 - val_loss: 2.9318 - val_accuracy: 0.7391\nEpoch 434/500\n6/6 [==============================] - 1s 96ms/step - loss: 6.3723e-08 - accuracy: 1.0000 - val_loss: 2.7758 - val_accuracy: 0.7391\nEpoch 435/500\n6/6 [==============================] - 1s 91ms/step - loss: 4.7684e-08 - accuracy: 1.0000 - val_loss: 2.6967 - val_accuracy: 0.7609\nEpoch 436/500\n6/6 [==============================] - 1s 108ms/step - loss: 5.0285e-08 - accuracy: 1.0000 - val_loss: 2.6357 - val_accuracy: 0.7500\nEpoch 437/500\n6/6 [==============================] - 1s 95ms/step - loss: 4.4216e-08 - accuracy: 1.0000 - val_loss: 2.6744 - val_accuracy: 0.7500\nEpoch 438/500\n6/6 [==============================] - 1s 90ms/step - loss: 3.9881e-08 - accuracy: 1.0000 - val_loss: 2.7326 - val_accuracy: 0.7500\nEpoch 439/500\n6/6 [==============================] - 1s 92ms/step - loss: 3.8147e-08 - accuracy: 1.0000 - val_loss: 2.7644 - val_accuracy: 0.7391\nEpoch 440/500\n6/6 [==============================] - 1s 104ms/step - loss: 3.9014e-08 - accuracy: 1.0000 - val_loss: 2.6316 - val_accuracy: 0.7500\nEpoch 441/500\n6/6 [==============================] - 1s 90ms/step - loss: 4.3349e-08 - accuracy: 1.0000 - val_loss: 2.7041 - val_accuracy: 0.7500\nEpoch 442/500\n6/6 [==============================] - 1s 91ms/step - loss: 3.5113e-08 - accuracy: 1.0000 - val_loss: 2.7492 - val_accuracy: 0.7391\nEpoch 443/500\n6/6 [==============================] - 1s 94ms/step - loss: 4.5950e-08 - accuracy: 1.0000 - val_loss: 2.6188 - val_accuracy: 0.7283\nEpoch 444/500\n6/6 [==============================] - 1s 97ms/step - loss: 5.0718e-08 - accuracy: 1.0000 - val_loss: 2.6223 - val_accuracy: 0.7283\nEpoch 445/500\n6/6 [==============================] - 1s 91ms/step - loss: 3.7713e-08 - accuracy: 1.0000 - val_loss: 2.7306 - val_accuracy: 0.7500\nEpoch 446/500\n6/6 [==============================] - 1s 102ms/step - loss: 3.1645e-08 - accuracy: 1.0000 - val_loss: 2.6660 - val_accuracy: 0.7500\nEpoch 447/500\n6/6 [==============================] - 1s 93ms/step - loss: 5.8087e-08 - accuracy: 1.0000 - val_loss: 2.5511 - val_accuracy: 0.7174\nEpoch 448/500\n6/6 [==============================] - 1s 93ms/step - loss: 1.5085e-07 - accuracy: 1.0000 - val_loss: 4.3668 - val_accuracy: 0.7283\nEpoch 449/500\n6/6 [==============================] - 1s 98ms/step - loss: 30.7258 - accuracy: 0.3927 - val_loss: 3.0479 - val_accuracy: 0.3478\nEpoch 450/500\n6/6 [==============================] - 1s 92ms/step - loss: 2.2671 - accuracy: 0.4000 - val_loss: 1.2655 - val_accuracy: 0.3804\nEpoch 451/500\n","name":"stdout"},{"output_type":"stream","text":"6/6 [==============================] - 1s 92ms/step - loss: 1.4749 - accuracy: 0.4800 - val_loss: 1.3095 - val_accuracy: 0.3696\nEpoch 452/500\n6/6 [==============================] - 1s 93ms/step - loss: 1.2340 - accuracy: 0.6218 - val_loss: 1.0498 - val_accuracy: 0.7065\nEpoch 453/500\n6/6 [==============================] - 1s 90ms/step - loss: 1.0964 - accuracy: 0.6473 - val_loss: 1.3317 - val_accuracy: 0.5435\nEpoch 454/500\n6/6 [==============================] - 1s 90ms/step - loss: 1.1403 - accuracy: 0.6145 - val_loss: 1.0843 - val_accuracy: 0.7065\nEpoch 455/500\n6/6 [==============================] - 1s 107ms/step - loss: 1.2745 - accuracy: 0.6764 - val_loss: 1.5763 - val_accuracy: 0.3696\nEpoch 456/500\n6/6 [==============================] - 1s 97ms/step - loss: 1.5123 - accuracy: 0.4182 - val_loss: 1.5717 - val_accuracy: 0.3696\nEpoch 457/500\n6/6 [==============================] - 1s 93ms/step - loss: 1.4722 - accuracy: 0.4182 - val_loss: 1.4767 - val_accuracy: 0.3696\nEpoch 458/500\n6/6 [==============================] - 1s 94ms/step - loss: 1.4182 - accuracy: 0.4182 - val_loss: 1.3768 - val_accuracy: 0.3696\nEpoch 459/500\n6/6 [==============================] - 1s 96ms/step - loss: 1.2326 - accuracy: 0.6327 - val_loss: 0.7974 - val_accuracy: 0.7065\nEpoch 460/500\n6/6 [==============================] - 1s 93ms/step - loss: 0.9215 - accuracy: 0.6800 - val_loss: 1.2135 - val_accuracy: 0.6739\nEpoch 461/500\n6/6 [==============================] - 1s 91ms/step - loss: 0.8524 - accuracy: 0.6800 - val_loss: 0.7772 - val_accuracy: 0.7717\nEpoch 462/500\n6/6 [==============================] - 1s 91ms/step - loss: 0.8132 - accuracy: 0.7018 - val_loss: 0.8024 - val_accuracy: 0.7065\nEpoch 463/500\n6/6 [==============================] - 1s 112ms/step - loss: 0.7665 - accuracy: 0.6945 - val_loss: 0.8300 - val_accuracy: 0.6957\nEpoch 464/500\n6/6 [==============================] - 1s 94ms/step - loss: 0.7267 - accuracy: 0.7018 - val_loss: 0.8657 - val_accuracy: 0.6957\nEpoch 465/500\n6/6 [==============================] - 1s 95ms/step - loss: 0.7253 - accuracy: 0.6982 - val_loss: 0.7728 - val_accuracy: 0.7500\nEpoch 466/500\n6/6 [==============================] - 1s 95ms/step - loss: 0.6718 - accuracy: 0.7382 - val_loss: 0.9130 - val_accuracy: 0.6196\nEpoch 467/500\n6/6 [==============================] - 1s 92ms/step - loss: 0.6216 - accuracy: 0.7491 - val_loss: 0.8542 - val_accuracy: 0.7174\nEpoch 468/500\n6/6 [==============================] - 1s 96ms/step - loss: 0.6242 - accuracy: 0.7491 - val_loss: 0.8715 - val_accuracy: 0.6848\nEpoch 469/500\n6/6 [==============================] - 1s 98ms/step - loss: 0.6068 - accuracy: 0.7491 - val_loss: 0.9634 - val_accuracy: 0.7065\nEpoch 470/500\n6/6 [==============================] - 1s 90ms/step - loss: 0.4990 - accuracy: 0.8000 - val_loss: 0.8448 - val_accuracy: 0.7609\nEpoch 471/500\n6/6 [==============================] - 1s 91ms/step - loss: 0.4728 - accuracy: 0.8000 - val_loss: 0.9442 - val_accuracy: 0.7065\nEpoch 472/500\n6/6 [==============================] - 1s 99ms/step - loss: 0.4405 - accuracy: 0.8545 - val_loss: 1.0384 - val_accuracy: 0.6957\nEpoch 473/500\n6/6 [==============================] - 1s 91ms/step - loss: 0.3807 - accuracy: 0.8436 - val_loss: 1.0168 - val_accuracy: 0.7174\nEpoch 474/500\n6/6 [==============================] - 1s 88ms/step - loss: 0.3031 - accuracy: 0.8982 - val_loss: 1.0736 - val_accuracy: 0.6304\nEpoch 475/500\n6/6 [==============================] - 1s 90ms/step - loss: 0.2783 - accuracy: 0.8982 - val_loss: 1.1698 - val_accuracy: 0.7174\nEpoch 476/500\n6/6 [==============================] - 1s 93ms/step - loss: 0.1892 - accuracy: 0.9491 - val_loss: 1.2402 - val_accuracy: 0.7065\nEpoch 477/500\n6/6 [==============================] - 1s 92ms/step - loss: 0.1460 - accuracy: 0.9564 - val_loss: 1.2960 - val_accuracy: 0.7283\nEpoch 478/500\n6/6 [==============================] - 1s 99ms/step - loss: 0.0979 - accuracy: 0.9927 - val_loss: 1.3380 - val_accuracy: 0.7283\nEpoch 479/500\n6/6 [==============================] - 1s 91ms/step - loss: 0.0694 - accuracy: 0.9964 - val_loss: 1.2767 - val_accuracy: 0.7500\nEpoch 480/500\n6/6 [==============================] - 1s 106ms/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 1.5187 - val_accuracy: 0.7391\nEpoch 481/500\n6/6 [==============================] - 1s 91ms/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 1.6222 - val_accuracy: 0.7065\nEpoch 482/500\n6/6 [==============================] - 1s 92ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 1.6161 - val_accuracy: 0.7283\nEpoch 483/500\n6/6 [==============================] - 1s 91ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 1.5139 - val_accuracy: 0.7283\nEpoch 484/500\n6/6 [==============================] - 1s 92ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.7732 - val_accuracy: 0.7065\nEpoch 485/500\n6/6 [==============================] - 1s 89ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.6213 - val_accuracy: 0.7283\nEpoch 486/500\n6/6 [==============================] - 1s 95ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.8289 - val_accuracy: 0.7065\nEpoch 487/500\n6/6 [==============================] - 1s 101ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.6541 - val_accuracy: 0.7065\nEpoch 488/500\n6/6 [==============================] - 1s 92ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.8666 - val_accuracy: 0.7065\nEpoch 489/500\n6/6 [==============================] - 1s 95ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.7868 - val_accuracy: 0.7065\nEpoch 490/500\n6/6 [==============================] - 1s 90ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.8205 - val_accuracy: 0.7065\nEpoch 491/500\n6/6 [==============================] - 1s 89ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.9279 - val_accuracy: 0.6957\nEpoch 492/500\n6/6 [==============================] - 1s 94ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8507 - val_accuracy: 0.7065\nEpoch 493/500\n6/6 [==============================] - 1s 92ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9177 - val_accuracy: 0.6957\nEpoch 494/500\n6/6 [==============================] - 1s 92ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9018 - val_accuracy: 0.6957\nEpoch 495/500\n6/6 [==============================] - 1s 93ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.9137 - val_accuracy: 0.7065\nEpoch 496/500\n6/6 [==============================] - 1s 89ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.9256 - val_accuracy: 0.6957\nEpoch 497/500\n6/6 [==============================] - 1s 119ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.9652 - val_accuracy: 0.7065\nEpoch 498/500\n6/6 [==============================] - 1s 90ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.9503 - val_accuracy: 0.6957\nEpoch 499/500\n6/6 [==============================] - 1s 92ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.9546 - val_accuracy: 0.6957\nEpoch 500/500\n6/6 [==============================] - 1s 93ms/step - loss: 9.2966e-04 - accuracy: 1.0000 - val_loss: 2.0071 - val_accuracy: 0.7065\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_new = x_test\ny_pred = model.predict_classes(x_new)\ny_pred[:10]","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"array([0, 0, 0, 0, 0, 1, 1, 1, 4, 1])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true = y_test.tolist()\n\nfor i in range(len(y_true)):\n    if equal_list(y_true[i], [1., 0., 0., 0., 0.]):\n        y_true[i] = 0\n    elif equal_list(y_true[i], [0., 1., 0., 0., 0.]):\n        y_true[i] = 1\n    elif equal_list(y_true[i], [0., 0., 1., 0., 0.]):\n        y_true[i] = 2\n    elif equal_list(y_true[i], [0., 0., 0., 1., 0.]):\n        y_true[i] = 3\n    elif equal_list(y_true[i], [0., 0., 0., 0., 1.]):\n        y_true[i] = 4\n        \nlen(y_true)","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"92"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = ConfusionMatrix(actual_vector=y_true, predict_vector=y_pred)\ncm.relabel(mapping={0:\"arabic\", 1:\"english\", 2:\"french\", 3:\"german\", 4:\"hindi\"})\nprint(cm)","execution_count":29,"outputs":[{"output_type":"stream","text":"Predict       arabic        english       french        german        hindi         \nActual\narabic        31            0             0             0             0             \n\nenglish       0             31            1             1             1             \n\nfrench        0             9             3             4             3             \n\ngerman        0             5             1             0             0             \n\nhindi         0             1             0             1             0             \n\n\n\n\n\nOverall Statistics : \n\n95% CI                                                            (0.61347,0.79957)\nACC Macro                                                         0.88261\nARI                                                               0.58636\nAUNP                                                              0.79989\nAUNU                                                              0.66694\nBangdiwala B                                                      0.72485\nBennett S                                                         0.63315\nCBA                                                               0.36636\nCSI                                                               -0.13129\nChi-Squared                                                       119.31383\nChi-Squared DF                                                    16\nConditional Entropy                                               0.6518\nCramer V                                                          0.56941\nCross Entropy                                                     2.12131\nF1 Macro                                                          0.405\nF1 Micro                                                          0.70652\nFNR Macro                                                         0.58607\nFNR Micro                                                         0.29348\nFPR Macro                                                         0.08005\nFPR Micro                                                         0.07337\nGwet AC1                                                          0.64693\nHamming Loss                                                      0.29348\nJoint Entropy                                                     2.55825\nKL Divergence                                                     0.21485\nKappa                                                             0.57172\nKappa 95% CI                                                      (0.43594,0.70751)\nKappa No Prevalence                                               0.41304\nKappa Standard Error                                              0.06928\nKappa Unbiased                                                    0.56528\nKrippendorff Alpha                                                0.56764\nLambda A                                                          0.65517\nLambda B                                                          0.67391\nMutual Information                                                1.0589\nNIR                                                               0.36957\nOverall ACC                                                       0.70652\nOverall CEN                                                       0.27005\nOverall J                                                         (1.77551,0.3551)\nOverall MCC                                                       0.59014\nOverall MCEN                                                      0.37218\nOverall RACC                                                      0.31474\nOverall RACCU                                                     0.32491\nP-Value                                                           0.0\nPPV Macro                                                         0.45478\nPPV Micro                                                         0.70652\nPearson C                                                         0.75142\nPhi-Squared                                                       1.29689\nRCI                                                               0.55543\nRR                                                                18.4\nReference Entropy                                                 1.90645\nResponse Entropy                                                  1.7107\nSOA1(Landis & Koch)                                               Moderate\nSOA2(Fleiss)                                                      Intermediate to Good\nSOA3(Altman)                                                      Moderate\nSOA4(Cicchetti)                                                   Fair\nSOA5(Cramer)                                                      Relatively Strong\nSOA6(Matthews)                                                    Moderate\nScott PI                                                          0.56528\nStandard Error                                                    0.04747\nTNR Macro                                                         0.91995\nTNR Micro                                                         0.92663\nTPR Macro                                                         0.41393\nTPR Micro                                                         0.70652\nZero-one Loss                                                     27\n\nClass Statistics :\n\nClasses                                                           arabic        english       french        german        hindi         \nACC(Accuracy)                                                     1.0           0.80435       0.80435       0.86957       0.93478       \nAGF(Adjusted F-score)                                             1.0           0.86984       0.39516       0.0           0.0           \nAGM(Adjusted geometric mean)                                      1.0           0.79093       0.64881       0             0             \nAM(Difference between automatic and manual classification)        0             12            -14           0             2             \nAUC(Area under the ROC curve)                                     1.0           0.82657       0.56525       0.46512       0.47778       \nAUCI(AUC value interpretation)                                    Excellent     Very Good     Poor          Poor          Poor          \nAUPR(Area under the PR curve)                                     1.0           0.79284       0.37895       0.0           0.0           \nBCD(Bray-Curtis dissimilarity)                                    0.0           0.06522       0.07609       0.0           0.01087       \nBM(Informedness or bookmaker informedness)                        1.0           0.65314       0.1305        -0.06977      -0.04444      \nCEN(Confusion entropy)                                            0             0.3069        0.57285       0.65028       0.59749       \nDOR(Diagnostic odds ratio)                                        None          29.62222      6.65625       0.0           0.0           \nDP(Discriminant power)                                            None          0.81135       0.45387       None          None          \nDPI(Discriminant power interpretation)                            None          Poor          Poor          None          None          \nERR(Error rate)                                                   0.0           0.19565       0.19565       0.13043       0.06522       \nF0.5(F0.5 score)                                                  1.0           0.71101       0.38462       0.0           0.0           \nF1(F1 score - harmonic mean of precision and sensitivity)         1.0           0.775         0.25          0.0           0.0           \nF2(F2 score)                                                      1.0           0.85165       0.18519       0.0           0.0           \nFDR(False discovery rate)                                         0.0           0.32609       0.4           1.0           1.0           \nFN(False negative/miss/type 2 error)                              0             3             16            6             2             \nFNR(Miss rate or false negative rate)                             0.0           0.08824       0.84211       1.0           1.0           \nFOR(False omission rate)                                          0.0           0.06522       0.18391       0.06977       0.02273       \nFP(False positive/type 1 error/false alarm)                       0             15            2             6             4             \nFPR(Fall-out or false positive rate)                              0.0           0.25862       0.0274        0.06977       0.04444       \nG(G-measure geometric mean of precision and sensitivity)          1.0           0.78387       0.30779       0.0           0.0           \nGI(Gini index)                                                    1.0           0.65314       0.1305        -0.06977      -0.04444      \nGM(G-mean geometric mean of specificity and sensitivity)          1.0           0.82217       0.39188       0.0           0.0           \nIBA(Index of balanced accuracy)                                   1.0           0.79114       0.02846       0.0           0.0           \nICSI(Individual classification success index)                     1.0           0.58568       -0.24211      -1.0          -1.0          \nIS(Information score)                                             1.56937       0.86673       1.53867       None          None          \nJ(Jaccard index)                                                  1.0           0.63265       0.14286       0.0           0.0           \nLS(Lift score)                                                    2.96774       1.82353       2.90526       0.0           0.0           \nMCC(Matthews correlation coefficient)                             1.0           0.63053       0.23302       -0.06977      -0.03178      \nMCCI(Matthews correlation coefficient interpretation)             Very Strong   Moderate      Negligible    Negligible    Negligible    \nMCEN(Modified confusion entropy)                                  0             0.41446       0.59964       0.65028       0.59749       \nMK(Markedness)                                                    1.0           0.6087        0.41609       -0.06977      -0.02273      \nN(Condition negative)                                             61            58            73            86            90            \nNLR(Negative likelihood ratio)                                    0.0           0.11902       0.86583       1.075         1.04651       \nNLRI(Negative likelihood ratio interpretation)                    Good          Fair          Negligible    Negligible    Negligible    \nNPV(Negative predictive value)                                    1.0           0.93478       0.81609       0.93023       0.97727       \nOC(Overlap coefficient)                                           1.0           0.91176       0.6           0.0           0.0           \nOOC(Otsuka-Ochiai coefficient)                                    1.0           0.78387       0.30779       0.0           0.0           \nOP(Optimized precision)                                           1.0           0.70128       0.08368       -0.13043      -0.06522      \nP(Condition positive or support)                                  31            34            19            6             2             \nPLR(Positive likelihood ratio)                                    None          3.52549       5.76316       0.0           0.0           \nPLRI(Positive likelihood ratio interpretation)                    None          Poor          Fair          Negligible    Negligible    \nPOP(Population)                                                   92            92            92            92            92            \nPPV(Precision or positive predictive value)                       1.0           0.67391       0.6           0.0           0.0           \nPRE(Prevalence)                                                   0.33696       0.36957       0.20652       0.06522       0.02174       \nQ(Yule Q - coefficient of colligation)                            None          0.93469       0.73878       -1.0          -1.0          \nQI(Yule Q interpretation)                                         None          Strong        Moderate      Negligible    Negligible    \nRACC(Random accuracy)                                             0.11354       0.18478       0.01122       0.00425       0.00095       \nRACCU(Random accuracy unbiased)                                   0.11354       0.18904       0.01701       0.00425       0.00106       \nTN(True negative/correct rejection)                               61            43            71            80            86            \nTNR(Specificity or true negative rate)                            1.0           0.74138       0.9726        0.93023       0.95556       \nTON(Test outcome negative)                                        61            46            87            86            88            \nTOP(Test outcome positive)                                        31            46            5             6             4             \nTP(True positive/hit)                                             31            31            3             0             0             \nTPR(Sensitivity, recall, hit rate, or true positive rate)         1.0           0.91176       0.15789       0.0           0.0           \nY(Youden index)                                                   1.0           0.65314       0.1305        -0.06977      -0.04444      \ndInd(Distance index)                                              0.0           0.27326       0.84255       1.00243       1.00099       \nsInd(Similarity index)                                            1.0           0.80678       0.40423       0.29117       0.2922        \n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_curve = history.history[\"loss\"]\nacc_curve = history.history[\"accuracy\"]\n\nacc_val_curve = history.history[\"val_accuracy\"]\nloss_val_curve = history.history[\"val_loss\"]\n\nplt.plot(loss_curve, label=\"Train\")\nplt.plot(loss_val_curve, label=\"Val\")\nplt.legend(loc='upper left')\nplt.title(\"Loss\")\nplt.show()\n\nplt.plot(acc_curve, label=\"Train\")\nplt.plot(acc_val_curve, label=\"Val\")\nplt.legend(loc='upper left')\nplt.title(\"Accuracy\")\nplt.show()","execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}